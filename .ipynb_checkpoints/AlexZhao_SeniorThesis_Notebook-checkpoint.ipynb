{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dimensions of Non Ordinary Experiences: Natural Language Processing of Trascendent Experience Reports\n",
    "\n",
    "`EAS 499: Senior Thesis`\n",
    "\n",
    "`University of Pennsylvania, Fall 2019`\n",
    "\n",
    "#### Author: **Alex Tianheng Zhao**  \n",
    "> `alexzhao@seas.upenn.edu`  \n",
    "> Department of Computer and Information, School of Engineering and Applied Science, University of Pennsylvania  \n",
    "> Department of Statistics, The Wharton School, University of Pennsylvania  \n",
    "> üåê[`personal website`](https://alextzhao.io), [`github`](https://github.com/alextzhao), [`linkedin`](https://www.linkedin.com/in/alextzhao)\n",
    "\n",
    "\n",
    "#### **Max Mintz, PhD**  \n",
    "> `mintz@cis.upenn.edu`  \n",
    "> Coordinator, Senior Thesis Program, Department of Computer and Information Science  \n",
    "> University of Pennsylvania  \n",
    "\n",
    "\n",
    "## **Thesis Advisors**\n",
    "> **Chris Callison-Burch, PhD**  \n",
    "> `ccb@upenn.edu`  \n",
    "> Department of Computer and Information Science (SEAS), University of Pennsylvania  \n",
    " \n",
    "> **Lyle Ungar, PhD**  \n",
    "> `ungar@cis.upenn.edu`  \n",
    "> Department of Computer and Information Science; additional appoints in the Departments of Bioengineering (SEAS); Genomics and Computational Biology (Penn Medicine); Operations, Informations, and Decisions (Wharton); Psychology (SAS), University of Pennsylvania  \n",
    "\n",
    "\n",
    "### **Useful Links:**\n",
    "- Thesis Related:\n",
    "    - [Thesis Master Document](https://docs.google.com/document/d/1dk1xXyfHqfdn5Tld-KZu7toiNYQeJHQv7BUlG7uSqP4/edit#)\n",
    "    - [Thesis Scratch Paper](https://docs.google.com/document/d/1BP5Z2J9tJvRJB5J-hthQIGrdSnD0Bcvctd7kHqbUUKw/edit?usp=sharing)  \n",
    "    - [Thesis Codebase](https://github.com/alextzhao/psychedelicNLP)\n",
    "- Helpful Tutorials and Tips\n",
    "     - Excellent Series from `Towards Data Science`:\n",
    "         - [A Practitioner's Guide to Natural Language Processing (Part I): Processing & Understanding Text](https://towardsdatascience.com/a-practitioners-guide-to-natural-language-processing-part-i-processing-understanding-text-9f4abfd13e72)\n",
    "         - [Feature Engineering: Continuous Numeric Data](https://towardsdatascience.com/understanding-feature-engineering-part-1-continuous-numeric-data-da4e47099a7b)\n",
    "         - [Feature Engineering: Categorical Data](https://homes.cs.washington.edu/~pedrod/papers/cacm12.pdf)\n",
    "         - [Feature Engineering: Text Data Basics](https://towardsdatascience.com/understanding-feature-engineering-part-3-traditional-methods-for-text-data-f6f7d70acd41)\n",
    "         - [Feature Engineering: Text Data Advanced](https://towardsdatascience.com/understanding-feature-engineering-part-4-deep-learning-methods-for-text-data-96c44370bbfa)\n",
    "     - [A few userful things to know about machine learning](https://homes.cs.washington.edu/~pedrod/papers/cacm12.pdf)\n",
    "     - [LDA: Excellent Talk by Christine Doig on Topic Models](http://chdoig.github.io/pygotham-topic-modeling/#/)\n",
    "     - [Markdown Cheatsheet](https://github.com/adam-p/markdown-here/wiki/Markdown-Cheatsheet#links)\n",
    "     - [Using R and Python together](https://stackoverflow.com/questions/39008069/r-and-python-in-one-jupyter-notebook); [python, R dataframe interoperability](https://rpy2.github.io/doc/latest/html/pandas.html); [R and python pipelining](https://blog.revolutionanalytics.com/2016/01/pipelining-r-python.html)\n",
    "     - [Translate dplyr to pandas](https://pandas.pydata.org/pandas-docs/stable/getting_started/comparison/comparison_with_r.html)\n",
    "     - [Basic pandas tutorial](https://pandas.pydata.org/pandas-docs/stable/getting_started/10min.html#min)\n",
    "     - [Recommended dependencies for pandas](https://pandas.pydata.org/pandas-docs/stable/install.html#install-recommended-dependencies)\n",
    "     - [Pandas: Working with Text Data](https://pandas.pydata.org/pandas-docs/stable/user_guide/text.html)  \n",
    "     - [sklearn reference](https://scikit-learn.org/stable/modules/classes.html): handy documentation, and provides broad-strokes ontology for machine learning techniques\n",
    "     - [Introduction to Machine Learning with sklearn](https://scikit-learn.org/stable/tutorial/basic/tutorial.html)\n",
    "     - [Sample pipeline for text feature extraction and evaluation](https://scikit-learn.org/stable/auto_examples/model_selection/grid_search_text_feature_extraction.html#sphx-glr-auto-examples-model-selection-grid-search-text-feature-extraction-py): using `sklearn`\n",
    "     - [Comparison of performances of different classifiers](https://scikit-learn.org/stable/auto_examples/classification/plot_classifier_comparison.html#sphx-glr-auto-examples-classification-plot-classifier-comparison-py): from `sklearn`, super cool\n",
    "     - TODO: [Citing sklearn](https://scikit-learn.org/stable/about.html#citing-scikit-learn)\n",
    "     - [Contributing to sklearn](https://scikit-learn.org/stable/developers/contributing.html)\n",
    "     - [Manually Creating a table of contents](https://medium.com/@sambozek/ipython-er-jupyter-table-of-contents-69bb72cf39d3)\n",
    "     - [Automaticaly Creating Table of Contents](https://jupyter-contrib-nbextensions.readthedocs.io/en/latest/nbextensions/toc2/README.html)\n",
    "     - [Python Data Science Handbook](https://github.com/jakevdp/PythonDataScienceHandbook): Free Jupyter Notebooks\n",
    "     - [Configuring jupyter notebook with extensions](https://github.com/Jupyter-contrib/jupyter_nbextensions_configurator)\n",
    "- Publishing my thesis:\n",
    "    - [Jupyter Notebook Viewer](https://nbviewer.jupyter.org/)\n",
    "   \n",
    "\n",
    "![Pandas Indexing Cheatsheet](./pandas_indexing_cheatsheet.png)\n",
    "- Notes to self:\n",
    "    - `~/opt/anaconda3/lib/python3.7/site-packages/jupyter_contrib_nbextensions/nbextensions/toc2` path to nbextensions toc2\n",
    "    - [fixing nbextensions](https://github.com/ipython-contrib/jupyter_contrib_nbextensions/issues/1090)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# -----------------------------    [ Front Matter End ]   ----------------------------------\n",
    "\n",
    "<br /> \n",
    "<br /> \n",
    "<br /> \n",
    "<br /> \n",
    "<br /> \n",
    "<br /> \n",
    "<br /> \n",
    "<br /> \n",
    "<br /> \n",
    "<br /> \n",
    "<br /> \n",
    "<br /> \n",
    "<br /> \n",
    "<br /> \n",
    "<br /> \n",
    "<br /> \n",
    "<br /> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of Contents\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Abstract\n",
    "\n",
    "Using natural language processing on approximately 30,000 reports of transcendent experiences, we examine and better understand the dimensions of non-ordinary states of consciousness. The primary data source is the Vaults of Erowid, which consists of approximately 25K psychedelic trip reports. Through this work, we identify clusters of subjective experiences, as well as dimensions of subjective experiences that are correlated with user affect, overall valence, and clinical significance. We also demonstrate the ability to predict (with fairly high confidence) the origins (i.e.: psychedelic drug of choice, set and setting) of such transcendent experiences.\n",
    "\n",
    "For link to the work in progress codebase, see the [public project github](https://github.com/alextzhao/psychedelicNLP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Definitions: What are psychedelics\n",
    "// todo insert brief legal background\n",
    "\n",
    "Psychedelics (from the Greek psyche: mind, delos: make visible, reveal, together meaning ‚Äúmind manifesting‚Äù, coined in a letter from Humphrey Osmond to Aldous Huxley), are ‚Äúsubstances that induce a heightened state of consciousness characterised by a hyperconnected brain state‚Äù (todo). The most well known ‚Äúclassical psychedelics‚Äù, some of which have been used by indigenous cultures for thousands of years, activate the serotonin system, in particular by agonizing the 5HT-2A serotonin receptor subtype. These classical psychedelics include Lysergic Acid Di-amide (LSD, semi-synthetic psychedelic derived from the ergot fungi), Psilocybin (inactive prodrug to the psychoactive Psilocin, found in certain mushrooms), Di-mythyltryptamine (DMT, the active ingredient in the powerful, indigenous Amazonian brew Ayahuasca), and Mescaline (found in Peyote Cactus). Newer psychedelics such as 2-CB, 5-Methoxy-Dimethyltryptamine (5-Meo-DMT, found in multiple plant species and most famously the Sonoran Desert Toad) are also often classified under the term hallucinogen or psychedelic. Other related drugs such as 3,4-Methylenedioxymethamphetamine (MDMA) are often referred to as psychedelic drugs, but are more correctly classified as an empathogen or entactogen (todo) (meaning ‚Äútouching within‚Äù,  from the Greek en: within), the Latin tactus: touch and the Greek -gen: produce)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Background, Significance, and Extensions\n",
    "// todo: discussion on mental health\n",
    "\n",
    "On September 4th, 2019, Johns Hopkins University launched the Johns Hopkins Center for Psychedelics and Consciousness Research, with $17 million dollars in research funding. The center is thought to be the largest of its kind in the world, and sets to study addition, PTSD, addiction, depression, anorexia nervosa, trauma, and other mental ‚Äúillnesses‚Äù with psychedelics and traditional forms of therapy. \n",
    "\n",
    "After decades of suppression and moral hazard, psychedelics are making a return to legitimate research as a novel and surprisingly effective treatment modality for multiple extremely difficult conditions, including but not limited to end of life anxiety (todo), treatment-resistant depression (todo), post traumatic stress disorder (PTSD) (todo), alcohol and nicotine addiction (todo), sexual and racial trauma, and alzheimer‚Äôs (todo). Psychedelics have also shown dramatic results for ‚Äúwell-people‚Äù, including being able to reliably induce ‚Äúmystical-type experiences‚Äù (todo), increase creativity, and is correlated with greatly enhanced feelings of religious devotion (todo). Beyond clinical studies, animal studies with octopi have demonstrated MDMA increasing feelings of social connectedness (todo); In vitro studies have shown enhanced neuroplasticity (todo Victor preprint), orchestrated brain activity; Brain imaging studies, primarily out of Imperial College London and University College London, have shown psychedelics quiet the default mode network (todo), induce hyperconnected and entropic brain states (todo), and proposed a mechanism for action for psychedelics, formalized as the Free Energy Principle and RHEBUS (todo). Selena Atasoy of Oxford University has also recently demonstrated that the brain under psychedelics has more high energy resonant states, while remaining hyper-coherent and highly orchestrated, using a novel technique called Connectome Specific Harmonic Waves (CSHW). The Qualia Research Institute (QRI) has also recently proposed the Symmetry Theory of Valence (STV), which posits that symmetries in resonant brain states as modelled by a high dimensional mathematical objects, is correlated with experiential valence.\n",
    "\n",
    "With all the exciting work being done in the psychedelics landscape (call it ‚Äúpsychedemia‚Äù), be it clinical, neuroscientific, or anthropological, little work has been done on understanding what the psychedelic trip actually consists of, and understanding qualitatively and quantitatively the dimensions of the psychedelic subjective experience. Current work by Imperial College and Oxford (todo) are showing promising results for understanding both the macro and micro phenomenology of psychedelic experiences. Using natural language as a low-dimensional, inadequately wanting proxy, we can begin to understand the hallmark subjective signatures of different substances, and potentially identify novel neuro-targets for clinical interventions to reduce suffering, as well as gain a deeper understanding of mechanisms of action for psychedelic substances, if such a mechanistic understanding is even possible. It is the sincere hope that through this work, we may begin to demystify the subjective dimensions that characterize psychedelic experiences, and lay the foundations for more informed clinical and societal support structures that may alleviate unnecessary mental suffering and enrich the lives of well-people.  \n",
    "\n",
    "This thesis seeks to extend the current work by using techniques from machine learning, and in particular natural language processing, on a corpus of psychedelic trip reports retrieved from multiple sources, including chiefly, the Vaults of Erowid. We will present the results factually, with minimal layers of interpretation and meticulous documentation for high reproducibility, clarifying our assumptions and processes whenever appropriate. It is our hope that this work may be open-sourced and beneficial to clinical researchers, psychologists, neuroscientists, machine learning engineers, social scientists, and the lay people community as a whole. If not for some deep, metaphysical takeaway, perhaps for some lighthearted, jovial pass time.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Natural Language Processing Pipeline\n",
    "\n",
    "![The NLP Pipeline](./images/infographic_nlp-pipeline.png)\n",
    "[`Infographic Source`](https://towardsdatascience.com/a-practitioners-guide-to-natural-language-processing-part-i-processing-understanding-text-9f4abfd13e72)\n",
    "\n",
    "This thesis employs the [CRISP-DM](https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.198.5133&rep=rep1&type=pdf) (Cross Industry Standard Process for Data Mining) pipeline, which is a widely used open standard by professional data scientists as a standard data mining approach\n",
    "\n",
    "![CRISP-DM Model](./images/infographic_CRISP-DM.png)\n",
    "[`CRISP-DM Model Infographic Source`](https://towardsdatascience.com/understanding-feature-engineering-part-1-continuous-numeric-data-da4e47099a7b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Acquisition\n",
    "\n",
    "TODO: Explain data source  \n",
    "TODO: Screenshot of Erowid  \n",
    "TODO: Explain scraping Erowid with Selenium and lxml  \n",
    "TODO: Explain extract the relavent information  \n",
    "TODO: Credits to Yev  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 00: Text pre-processing\n",
    "\n",
    "TODO: EDA before data cleaning to see how dirty the data is  \n",
    "TODO: Move data cleaning to this step, before we even go into word clouds!!  \n",
    "TODO: Implement the following that have not been implemented yet!\n",
    "\n",
    "Overview:\n",
    "- Remove rougue `html`/`xml` tags; use `Beautiful Soup`\n",
    "- Remove numbers (optional); Use `regex`\n",
    "- Normalize accented characters; Use `unicodedata.normalize` and built in `sklearn` functionality\n",
    "- Remove extra spaces, use `str.strip()`\n",
    "- Make all text lowercase; use `lower()`\n",
    "- Expanding contractions (optional, as per Lyle Ungar)\n",
    "- Remove special characters\n",
    "- NOTE: only unigrams considered at this stage; ngram analysis down the line\n",
    "- Stemming\n",
    "- Lemmatization\n",
    "- Remove stopwords\n",
    "- TokenizationUse; use `nltk` or `spaCy`\n",
    "- Save cleaned text to disk: e.g.: `news_df.to_csv('news.csv', index=False, encoding='utf-8')`; OR use pickle dump\n",
    "![Stemming Example](./images/infographic_stemming-inflections.png)\n",
    "[`Stemming Graphics Source`](https://towardsdatascience.com/a-practitioners-guide-to-natural-language-processing-part-i-processing-understanding-text-9f4abfd13e72)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code from: https://towardsdatascience.com/understanding-feature-engineering-part-3-traditional-methods-for-text-data-f6f7d70acd41\n",
    "# TODO: Adapt\n",
    "# TODO: Vectorize for pandas dataframe\n",
    "wpt = nltk.WordPunctTokenizer()\n",
    "stop_words = nltk.corpus.stopwords.words('english')\n",
    "\n",
    "def normalize_document(doc):\n",
    "    # lower case and remove special characters\\whitespaces\n",
    "    doc = re.sub(r'[^a-zA-Z\\s]', '', doc, re.I|re.A)\n",
    "    doc = doc.lower()\n",
    "    doc = doc.strip()\n",
    "    # tokenize document\n",
    "    tokens = wpt.tokenize(doc)\n",
    "    # filter stopwords out of document\n",
    "    filtered_tokens = [token for token in tokens if token not in stop_words]\n",
    "    # re-create document from filtered tokens\n",
    "    doc = ' '.join(filtered_tokens)\n",
    "    return doc\n",
    "\n",
    "normalize_corpus = np.vectorize(normalize_document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'My system keep crash hi crash yesterday, our crash daili'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: Stemming is super easy!\n",
    "# From: https://towardsdatascience.com/a-practitioners-guide-to-natural-language-processing-part-i-processing-understanding-text-9f4abfd13e72\n",
    "def simple_stemmer(text):\n",
    "    ps = nltk.porter.PorterStemmer()\n",
    "    text = ' '.join([ps.stem(word) for word in text.split()])\n",
    "    return text\n",
    "\n",
    "simple_stemmer(\"My system keeps crashing his crashed yesterday, ours crashes daily\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Lemmatization\n",
    "def lemmatize_text(text):\n",
    "    text = nlp(text)\n",
    "    text = ' '.join([word.lemma_ if word.lemma_ != '-PRON-' else word.text for word in text])\n",
    "    return text\n",
    "\n",
    "lemmatize_text(\"My system keeps crashing! his crashed yesterday, ours crashes daily\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 0: Data Wrangling, Text Parsing, and Exploratory Data Analysis (EDA)\n",
    "\n",
    "\n",
    "TODO: Exploratory Data Analysis  \n",
    "TODO: For feature engineering, can use dimensionality reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sets up the ability to use R in a jupyter notebook\n",
    "# https://stackoverflow.com/questions/39008069/r-and-python-in-one-jupyter-notebook\n",
    "# To use R, add %%R to the beginning of a cell, before any code and any comments\n",
    "%load_ext rpy2.ipython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R[write to console]: Loading required package: pacman\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%R\n",
    "# Installs the proper R packages\n",
    "if(!require('pacman')) {\n",
    "  install.packages('pacman', repos = \"http://cran.us.r-project.org\")\n",
    "}\n",
    "pacman::p_load(dplyr, leaps, car, tidyverse, GGally, reshape2, data.table, ggcorrplot, bestglm, glmnet, mapproj, pROC, data.tale, tm, SnowballC, wordcloud, RColorBrewer, reshape2) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] 19924\n"
     ]
    }
   ],
   "source": [
    "%%R\n",
    "\n",
    "## Read in trip reports\n",
    "tripReports <- fread(\"trips.csv\")\n",
    "tripReports.df <- as.data.frame(tripReports)\n",
    "# glimpse(tripReports)\n",
    "\n",
    "nrow(tripReports)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "# Examine the substances present in the dataset\n",
    "tripReports %>% select(substance) %>% write.table(file = \"substances-all\", append=FALSE, col.names = FALSE, row.names = FALSE, sep = \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observations: 19,924\n",
      "Variables: 24\n",
      "$ report                    \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m \"After having had some success with other f‚Ä¶\n",
      "$ title                     \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m \"Sideways World\", \"Physical Wellbeing = Cru‚Ä¶\n",
      "$ substance                 \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m \"salvia divinorum (5x extract)\", \"mushrooms‚Ä¶\n",
      "$ substance.mushrooms       \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0‚Ä¶\n",
      "$ substance.lsd             \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0‚Ä¶\n",
      "$ substance.mescaline       \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0‚Ä¶\n",
      "$ substance.cannabis        \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0‚Ä¶\n",
      "$ substance.mdma            \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0‚Ä¶\n",
      "$ substance.ayahuasca       \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0‚Ä¶\n",
      "$ substance.nitrous_oxide   \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0‚Ä¶\n",
      "$ substance.salvia          \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0‚Ä¶\n",
      "$ substance.methamphetamine \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0‚Ä¶\n",
      "$ substance.dmt             \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0‚Ä¶\n",
      "$ substance.5_meo_dmt       \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0‚Ä¶\n",
      "$ substance.alcohol         \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0‚Ä¶\n",
      "$ substance.ketamine        \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0‚Ä¶\n",
      "$ substance.ibogaine        \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0‚Ä¶\n",
      "$ substance.pcp             \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0‚Ä¶\n",
      "$ substance.kava            \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0‚Ä¶\n",
      "$ substance.kratom          \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0‚Ä¶\n",
      "$ substance.morning_glory   \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0‚Ä¶\n",
      "$ substance.syrian_rue      \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0‚Ä¶\n",
      "$ substance.unknown         \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0‚Ä¶\n",
      "$ substance.UNK             \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0‚Ä¶\n"
     ]
    }
   ],
   "source": [
    "%%R\n",
    "\n",
    "## Manipulate the dataframe to have 1 hot encoding for substances\n",
    "tripReports$substance <- tolower(tripReports$substance)\n",
    "tripReports <- as.data.frame(tripReports)\n",
    "substances.of.interest <- c(\"substance.mushrooms\", \"substance.lsd\", \"substance.mescaline\", \"substance.cannabis\", \"substance.mdma\", \"substance.ayahuasca\", \"substance.nitrous_oxide\", \"substance.salvia\", \"substance.methamphetamine\", \"substance.dmt\", \"substance.5_meo_dmt\", \"substance.alcohol\", \"substance.ketamine\", \"substance.ibogaine\", \"substance.pcp\", \"substance.kava\", \"substance.kratom\", \"substance.morning_glory\", \"substance.syrian_rue\", \"substance.unknown\", \"substance.UNK\")\n",
    "\n",
    "for (sub in substances.of.interest) {\n",
    "  tripReports[sub] = 0\n",
    "}\n",
    "\n",
    "### Adding one hot encodings to the substances\n",
    "tripReports$substance.mushrooms[grepl(\"mushroom|mushhrooms|mushooms|psilocin|psilocybin|psilocybe\", tripReports$substance)] <- 1\n",
    "tripReports$substance.lsd[grepl(\"lysergic acid|lsd\", tripReports$substance)] <- 1\n",
    "tripReports$substance.mescaline[grepl(\"mescaline|peyote\", tripReports$substance)] <- 1\n",
    "tripReports$substance.cannabis[grepl(\"cannabis|canabis|cannabbis|cannabinoid|cannabus|cannibis|cannibus| thc \", tripReports$substance)] <- 1\n",
    "tripReports$substance.mdma[grepl(\"mdma|ecstacy|ecstasy|ectasy|molly\", tripReports$substance)] <- 1\n",
    "tripReports$substance.ayahuasca[grepl(\"ayahuasca|ayahausca|ayahusca|p. viridis|p.viridis|b.caapi|b. caapi|cappi|viridis\", tripReports$substance)] <- 1\n",
    "tripReports$substance.nitrous_oxide[grepl(\"nitric|nitrites|nitrogen|nitrous|whippets\", tripReports$substance)] <- 1\n",
    "tripReports$substance.salvia[grepl(\"salia|saliva|salivia|sally|salva|salvia|salvinorin\", tripReports$substance)] <- 1\n",
    "tripReports$substance.methamphetamine[grepl(\"met|meth|methampetamine|methamphetamine|speed\", tripReports$substance)] <- 1\n",
    "# dmt\n",
    "tripReports$substance.dmt[grepl(\"nn-dmt\", tripReports$substance)] <- 1\n",
    "tripReports$substance.dmt[tripReports$substance == \"dmt\"] <- 1 # cannot just grep dmt otherwise this will include 5-meo-dmt\n",
    "#5-meo-dmt\n",
    "tripReports$substance.5_meo_dmt[grepl(\"5 meo-dmt|5-meo dmt|5-meo-dmt|5meo-dmt\", tripReports$substance)] <- 1\n",
    "tripReports$substance.alcohol[grepl(\"alchohol|alcohol\", tripReports$substance)] <- 1\n",
    "tripReports$substance.ketamine[grepl(\"ketamin|ketamine\", tripReports$substance)] <- 1\n",
    "tripReports$substance.ibogaine[grepl(\"iboga|ibogaine\", tripReports$substance)] <- 1\n",
    "tripReports$substance.pcp[grepl(\"pcp\", tripReports$substance)] <- 1\n",
    "tripReports$substance.kava[grepl(\"kava\", tripReports$substance)] <- 1\n",
    "tripReports$substance.kratom[grepl(\"kratom\", tripReports$substance)] <- 1\n",
    "tripReports$substance.morning_glory[grepl(\"glory|glories\", tripReports$substance)] <- 1\n",
    "tripReports$substance.syrian_rue[grepl(\"syrian rue|rue\", tripReports$substance)] <- 1\n",
    "tripReports$substance.unknown[grepl(\"unknown|unidentified|unkown\", tripReports$substance)] <- 1\n",
    "\n",
    "glimpse(tripReports)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   substance count\n",
      "1         substance.cannabis  3110\n",
      "2        substance.mushrooms  1686\n",
      "3           substance.salvia  1556\n",
      "4             substance.mdma  1188\n",
      "5              substance.lsd  1131\n",
      "6  substance.methamphetamine   929\n",
      "7          substance.alcohol   928\n",
      "8    substance.morning_glory   427\n",
      "9    substance.nitrous_oxide   300\n",
      "10       substance.5_meo_dmt   297\n",
      "11      substance.syrian_rue   293\n",
      "12        substance.ketamine   289\n",
      "13          substance.kratom   207\n",
      "14       substance.ayahuasca   172\n",
      "15             substance.dmt   167\n",
      "16            substance.kava   167\n",
      "17             substance.pcp    81\n",
      "18       substance.mescaline    73\n",
      "19         substance.unknown    47\n",
      "20        substance.ibogaine    43\n",
      "21             substance.UNK     0\n"
     ]
    }
   ],
   "source": [
    "%%R\n",
    "\n",
    "## Number of reports containing each substance: NOTE: a report might have more than one substance\n",
    "tripSubstances <- tripReports %>% select(-report, -title, -substance)\n",
    "tripReportsCount <- data.frame(substance = names(tripSubstances), count = colSums(tripSubstances))\n",
    "tripReportsCountSorted <- tripReportsCount %>% arrange(desc(count))\n",
    "tripReportsCountSorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observations: 19,924\n",
      "Variables: 25\n",
      "$ report                    \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m \"After having had some success with other f‚Ä¶\n",
      "$ title                     \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m \"Sideways World\", \"Physical Wellbeing = Cru‚Ä¶\n",
      "$ substance                 \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m \"salvia divinorum (5x extract)\", \"mushrooms‚Ä¶\n",
      "$ substance.mushrooms       \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0‚Ä¶\n",
      "$ substance.lsd             \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0‚Ä¶\n",
      "$ substance.mescaline       \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0‚Ä¶\n",
      "$ substance.cannabis        \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0‚Ä¶\n",
      "$ substance.mdma            \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0‚Ä¶\n",
      "$ substance.ayahuasca       \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0‚Ä¶\n",
      "$ substance.nitrous_oxide   \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0‚Ä¶\n",
      "$ substance.salvia          \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0‚Ä¶\n",
      "$ substance.methamphetamine \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0‚Ä¶\n",
      "$ substance.dmt             \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0‚Ä¶\n",
      "$ substance.5_meo_dmt       \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0‚Ä¶\n",
      "$ substance.alcohol         \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0‚Ä¶\n",
      "$ substance.ketamine        \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0‚Ä¶\n",
      "$ substance.ibogaine        \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0‚Ä¶\n",
      "$ substance.pcp             \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0‚Ä¶\n",
      "$ substance.kava            \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0‚Ä¶\n",
      "$ substance.kratom          \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0‚Ä¶\n",
      "$ substance.morning_glory   \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0‚Ä¶\n",
      "$ substance.syrian_rue      \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0‚Ä¶\n",
      "$ substance.unknown         \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0‚Ä¶\n",
      "$ substance.UNK             \u001b[3m\u001b[90m<dbl>\u001b[39m\u001b[23m 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0‚Ä¶\n",
      "$ substance.unique_label    \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m \"substance.salvia\", \"substance.mushrooms\", ‚Ä¶\n"
     ]
    }
   ],
   "source": [
    "%%R\n",
    "\n",
    "## Find reports with only one unique substance\n",
    "\n",
    "tripReports$substance.unique_label <- \"NA\"\n",
    "# glimpse(tripReports)\n",
    "uniqueSubstanceRows <- tripReports %>% select(-report, -title, -substance, -substance.unique_label) %>% rowSums() == 1\n",
    "\n",
    "for (row in 1:nrow(tripReports)) {\n",
    "  # this row contains a unique substance\n",
    "  if (uniqueSubstanceRows[row]) {\n",
    "    for (substance in substances.of.interest) {\n",
    "      if (tripReports[row, substance] == 1) {\n",
    "        tripReports[row, ]$substance.unique_label<- substance\n",
    "      } \n",
    "    }\n",
    "  }\n",
    "}\n",
    "\n",
    "glimpse(tripReports)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "From cffi callback <function _processevents at 0x10cb41dd0>:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/alextzhao/opt/anaconda3/lib/python3.7/site-packages/rpy2/rinterface_lib/callbacks.py\", line 262, in _processevents\n",
      "    @ffi_proxy.callback(ffi_proxy._processevents_def,\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "%%R\n",
    "\n",
    "# TEMP, SAVE: Use this code to save the encoded table for future use\n",
    "save(tripReports, file=\"tripReportsEncoded.Rda\")\n",
    "write.table(tripReports, file=\"tripReportsEncodedTable\", sep = \";;\", row.names = TRUE, col.names = TRUE )\n",
    "write.csv(tripReports, file=\"tripReportsEncoded.csv\", sep = \",\", row.names = TRUE, col.names = TRUE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observations: 21\n",
      "Variables: 2\n",
      "$ substance \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m \"NA\", \"substance.cannabis\", \"substance.salvia\", \"substance.‚Ä¶\n",
      "$ count     \u001b[3m\u001b[90m<int>\u001b[39m\u001b[23m 11569, 1609, 1270, 1094, 747, 746, 696, 409, 328, 250, 171,‚Ä¶\n"
     ]
    }
   ],
   "source": [
    "%%R\n",
    "\n",
    "#### Create a data frame that combines the count for reports containing a substance and reports that are uniquely a single substance\n",
    "tripReportsUniqueSubstanceCountSorted <- tripReports %>% group_by(substance.unique_label) %>% summarise(count = n()) %>% arrange(desc(count))\n",
    "# glimpse(tripReportsCountSorted)\n",
    "colnames(tripReportsUniqueSubstanceCountSorted) = c(\"substance\", \"count\")\n",
    "tripReportsUniqueSubstanceCountSorted %>% glimpse()\n",
    "\n",
    "tripReportsCount_merged <- merge(tripReportsCountSorted, tripReportsUniqueSubstanceCountSorted, by=\"substance\")\n",
    "colnames(tripReportsCount_merged) = c(\"substance\", \"n_includes_substance\", \"n_single_substance\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   substance n_includes_substance n_single_substance\n",
      "1         substance.cannabis                 3110               1609\n",
      "2        substance.mushrooms                 1686               1094\n",
      "3           substance.salvia                 1556               1270\n",
      "4             substance.mdma                 1188                747\n",
      "5              substance.lsd                 1131                696\n",
      "6  substance.methamphetamine                  929                746\n",
      "7          substance.alcohol                  928                409\n",
      "8    substance.morning_glory                  427                328\n",
      "9    substance.nitrous_oxide                  300                155\n",
      "10       substance.5_meo_dmt                  297                250\n",
      "11      substance.syrian_rue                  293                164\n",
      "12        substance.ketamine                  289                170\n",
      "13          substance.kratom                  207                171\n",
      "14       substance.ayahuasca                  172                114\n",
      "15             substance.dmt                  167                167\n",
      "16            substance.kava                  167                131\n",
      "17             substance.pcp                   81                 38\n",
      "18       substance.mescaline                   73                 44\n",
      "19         substance.unknown                   47                 13\n",
      "20        substance.ibogaine                   43                 39\n"
     ]
    }
   ],
   "source": [
    "%%R\n",
    "\n",
    "# EXPORT: Table of selected substances and their counts\n",
    "tripReportsCount_merged %>% arrange(desc(n_includes_substance))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R[write to console]: Using substance as id variables\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%R\n",
    "\n",
    "## This data frame that encodes how many trip reports contains a substance and how many reports are uniquely such a substance'\n",
    "tripReportsCount_merged.long <- reshape2::melt(tripReportsCount_merged)\n",
    "# EXPORT: Graph of distribution of substances\n",
    "tripReportsCount_merged.long %>% ggplot( aes(x = reorder(substance, -value), y = value, fill=variable)) + geom_bar(stat=\"identity\", position = \"dodge\") + theme(axis.text.x = element_text(angle = 67.5, hjust = 1)) + ggtitle(\"Count of Substances Present in Trip Reports\") + xlab(\"substance\") + ylab(\"count\") + labs(fill = \"Number of Reports\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO data wrangling + insights\n",
    "\n",
    "- average length of trip reports, character level + word level\n",
    "- mistribution of the length of trip reports\n",
    "- most frequently co-consumed substances\n",
    "- distribution of the number of labels for different reports\n",
    "- distribution of the number of labels for each substance: e.g.: are reports with `cannabis` frequently not just cannabis? normalize using proportion of trip reports;\n",
    "- think more critically about treatment of longtail; do we simply label substances not within the top 20 substances as `<UNK>`? If so, how do we treat them in bayesian methods? My intuition is telling me that I should include all of them in trip report generation, but not in classification tasks;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 001: Understanding Language Syntax and Structure\n",
    "[Referece](https://towardsdatascience.com/a-practitioners-guide-to-natural-language-processing-part-i-processing-understanding-text-9f4abfd13e72)\n",
    "- POS tagging: What are the top nouns, verbs, adjectives etc. associated with each substance?\n",
    "- Shallow parsing or chunking\n",
    "- Constituency Parsing\n",
    "- Dependency Parsing\n",
    "\n",
    "# Part 002: Named Entity Recognition\n",
    "\n",
    "- TODO: This can absolutely be part of EDA!!\n",
    "\n",
    "![Named Entity Recognition Example](./images/infographic_NER.png)\n",
    "\n",
    "# Part 003: Sentiment Analysis of Trip Reports\n",
    "\n",
    "- TODO: Show distribution of sentiment across all trip reports\n",
    "\n",
    "# Part 004: Simple Bag of Words Model\n",
    "\n",
    "- TODO: Bag of words is SO easy with `sklearn` and `pandas`(mostly for display purposes)  \n",
    "- TODO: Bigrams and Trigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Example BOW's Code\n",
    "# Code from: https://towardsdatascience.com/understanding-feature-engineering-part-3-traditional-methods-for-text-data-f6f7d70acd41\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "cv = CountVectorizer(min_df=0., max_df=1.)\n",
    "cv_matrix = cv.fit_transform(norm_corpus)\n",
    "cv_matrix = cv_matrix.toarray()\n",
    "\n",
    "# get all unique words in the corpus\n",
    "vocab = cv.get_feature_names()\n",
    "# show document feature vectors\n",
    "pd.DataFrame(cv_matrix, columns=vocab)\n",
    "\n",
    "############################################\n",
    "## Ngram model extensions\n",
    "# you can set the n-gram range to 1,2 to get unigrams as well as bigrams\n",
    "bv = CountVectorizer(ngram_range=(2,2))\n",
    "bv_matrix = bv.fit_transform(norm_corpus)\n",
    "\n",
    "bv_matrix = bv_matrix.toarray()\n",
    "vocab = bv.get_feature_names()\n",
    "pd.DataFrame(bv_matrix, columns=vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 005: TFIDF Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'norm_corpus' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-50-05f8d2d3b287>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTfidfVectorizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmin_df\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_df\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_idf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mtv_matrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnorm_corpus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mtv_matrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtv_matrix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'norm_corpus' is not defined"
     ]
    }
   ],
   "source": [
    "# TODO: Sample TFIDF Code from: https://towardsdatascience.com/understanding-feature-engineering-part-3-traditional-methods-for-text-data-f6f7d70acd41\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tv = TfidfVectorizer(min_df=0., max_df=1., use_idf=True)\n",
    "tv_matrix = tv.fit_transform(norm_corpus)\n",
    "tv_matrix = tv_matrix.toarray()\n",
    "\n",
    "vocab = tv.get_feature_names()\n",
    "pd.DataFrame(np.round(tv_matrix, 2), columns=vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 006: Document Similarity Matrix\n",
    "- TODO: We can use this for clustering and obtain the \"cononical\" trip report for different categories\n",
    "- Cosine similarity\n",
    "- TODO: Other similarity measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Sample code from https://towardsdatascience.com/understanding-feature-engineering-part-3-traditional-methods-for-text-data-f6f7d70acd41\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "similarity_matrix = cosine_similarity(tv_matrix)\n",
    "similarity_df = pd.DataFrame(similarity_matrix)\n",
    "similarity_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 007: Clustering documents based on TF and TFIDF features\n",
    "- TODO: Agglomerative Hiearchical Clustering\n",
    "- TODO: KNN (?) - Probably more of a classification algorithm\n",
    "- TODO: Search up state of the art document clustering techniques\n",
    "- TODO: K Means clustering; \"There are multiple ways to select the optimal value of k like using the Sum of Squared Errors metric, Silhouette Coefficients and the Elbow method\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'similarity_matrix' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-54-0cece96fdad0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcluster\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhierarchy\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdendrogram\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlinkage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mZ\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlinkage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msimilarity_matrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ward'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m pd.DataFrame(Z, columns=['Document\\Cluster 1', 'Document\\Cluster 2', \n\u001b[1;32m      8\u001b[0m                          'Distance', 'Cluster Size'], dtype='object')\n",
      "\u001b[0;31mNameError\u001b[0m: name 'similarity_matrix' is not defined"
     ]
    }
   ],
   "source": [
    "# TODO\n",
    "# Example of Agglomerative Hiearchical Clustering \n",
    "# Source: https://towardsdatascience.com/understanding-feature-engineering-part-3-traditional-methods-for-text-data-f6f7d70acd41\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "\n",
    "Z = linkage(similarity_matrix, 'ward')\n",
    "pd.DataFrame(Z, columns=['Document\\Cluster 1', 'Document\\Cluster 2', \n",
    "                         'Distance', 'Cluster Size'], dtype='object')\n",
    "\n",
    "\n",
    "\n",
    "###### Visualizing the clustering process\n",
    "plt.figure(figsize=(8, 3))\n",
    "plt.title('Hierarchical Clustering Dendrogram')\n",
    "plt.xlabel('Data point')\n",
    "plt.ylabel('Distance')\n",
    "dendrogram(Z)\n",
    "plt.axhline(y=1.0, c='k', ls='--', lw=0.5)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Z' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-55-37f3dcb1584c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmax_dist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mcluster_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfcluster\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mZ\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_dist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'distance'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mcluster_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcluster_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ClusterLabel'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcorpus_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcluster_labels\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Z' is not defined"
     ]
    }
   ],
   "source": [
    "# TODO: Obtain cluster levels\n",
    "# Source: https://towardsdatascience.com/understanding-feature-engineering-part-3-traditional-methods-for-text-data-f6f7d70acd41\n",
    "# TODO: Compare the automatic clusters with the substance multilables\n",
    "# TODO: Can use a \"vector\" of the labels as a training label?\n",
    "from scipy.cluster.hierarchy import fcluster\n",
    "max_dist = 1.0\n",
    "\n",
    "cluster_labels = fcluster(Z, max_dist, criterion='distance')\n",
    "cluster_labels = pd.DataFrame(cluster_labels, columns=['ClusterLabel'])\n",
    "pd.concat([corpus_df, cluster_labels], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 008: Clustering based on LDA features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Example code for clustering with LDA embeddings\n",
    "# Source: https://towardsdatascience.com/understanding-feature-engineering-part-3-traditional-methods-for-text-data-f6f7d70acd41\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "km = KMeans(n_clusters=3, random_state=0)\n",
    "km.fit_transform(features)\n",
    "cluster_labels = km.labels_\n",
    "cluster_labels = pd.DataFrame(cluster_labels, columns=['ClusterLabel'])\n",
    "pd.concat([corpus_df, cluster_labels], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: Visualizing Erowid Corpus with Word Clouds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Word Clouds are an intuitively visual way to present vast amounts of textual information, revealing the key themes conveyed in a collection of documents. Prima facie, generating word clouds feel like a simple problem, yet very quickly deeper considerations arise, including (1) using appropriate preprocessing (stop words, stemming, lemmatization), (2) whether to include documents of class $j \\neq i$ when constructing a word cloud for documents of class, and (3) how to scale tokens, given (1) and (2). In this section, we explore combinations of different approaches, and conclude that the most suitable approach depends on our philosophy in constructing these word clouds."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Baseline Wordclouds\n",
    "\n",
    "For our baselines word clouds for documents of class i, we perform basic stopwords removal, with no stemming and lemmatization. We use: \n",
    "- Token raw frequency (not considering other classes $\\neq i$)\n",
    "- TF-IDF weighting (considering other classes $j \\neq i$)\n",
    "\n",
    "Note that since each trip report may contain multiple classes, we will include a document that contains k classes in k word clouds.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.0 | Getting to know pandas and our dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>report</th>\n",
       "      <th>title</th>\n",
       "      <th>substance</th>\n",
       "      <th>substance_mushrooms</th>\n",
       "      <th>substance_lsd</th>\n",
       "      <th>substance_mescaline</th>\n",
       "      <th>substance_cannabis</th>\n",
       "      <th>substance_mdma</th>\n",
       "      <th>substance_ayahuasca</th>\n",
       "      <th>substance_nitrous_oxide</th>\n",
       "      <th>...</th>\n",
       "      <th>substance_ketamine</th>\n",
       "      <th>substance_ibogaine</th>\n",
       "      <th>substance_pcp</th>\n",
       "      <th>substance_kava</th>\n",
       "      <th>substance_kratom</th>\n",
       "      <th>substance_morning_glory</th>\n",
       "      <th>substance_syrian_rue</th>\n",
       "      <th>substance_unknown</th>\n",
       "      <th>substance_unk</th>\n",
       "      <th>substance_unique_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>After having had some success with other forms...</td>\n",
       "      <td>Sideways World</td>\n",
       "      <td>salvia divinorum (5x extract)</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>substance.salvia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Me and a couple of my buddies decided one nigh...</td>\n",
       "      <td>Physical Wellbeing = Crucial</td>\n",
       "      <td>mushrooms</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>substance.mushrooms</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>My girlfriend and I had been saving the methyl...</td>\n",
       "      <td>The Artful Dodger</td>\n",
       "      <td>methylone</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>substance.methamphetamine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>I just want to warn anybody taking Lithium (or...</td>\n",
       "      <td>Seizure Inducing Combo</td>\n",
       "      <td>lsd &amp; lithium</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>substance.lsd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>I have had several attempts before this to bre...</td>\n",
       "      <td>Enlightenment Through a Chemical Catalyst</td>\n",
       "      <td>5-meo-dmt</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>substance.5_meo_dmt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              report  \\\n",
       "1  After having had some success with other forms...   \n",
       "2  Me and a couple of my buddies decided one nigh...   \n",
       "3  My girlfriend and I had been saving the methyl...   \n",
       "4  I just want to warn anybody taking Lithium (or...   \n",
       "5  I have had several attempts before this to bre...   \n",
       "\n",
       "                                       title                      substance  \\\n",
       "1                             Sideways World  salvia divinorum (5x extract)   \n",
       "2               Physical Wellbeing = Crucial                      mushrooms   \n",
       "3                          The Artful Dodger                      methylone   \n",
       "4                     Seizure Inducing Combo                  lsd & lithium   \n",
       "5  Enlightenment Through a Chemical Catalyst                      5-meo-dmt   \n",
       "\n",
       "   substance_mushrooms  substance_lsd  substance_mescaline  \\\n",
       "1                    0              0                    0   \n",
       "2                    1              0                    0   \n",
       "3                    0              0                    0   \n",
       "4                    0              1                    0   \n",
       "5                    0              0                    0   \n",
       "\n",
       "   substance_cannabis  substance_mdma  substance_ayahuasca  \\\n",
       "1                   0               0                    0   \n",
       "2                   0               0                    0   \n",
       "3                   0               0                    0   \n",
       "4                   0               0                    0   \n",
       "5                   0               0                    0   \n",
       "\n",
       "   substance_nitrous_oxide  ...  substance_ketamine  substance_ibogaine  \\\n",
       "1                        0  ...                   0                   0   \n",
       "2                        0  ...                   0                   0   \n",
       "3                        0  ...                   0                   0   \n",
       "4                        0  ...                   0                   0   \n",
       "5                        0  ...                   0                   0   \n",
       "\n",
       "   substance_pcp  substance_kava  substance_kratom  substance_morning_glory  \\\n",
       "1              0               0                 0                        0   \n",
       "2              0               0                 0                        0   \n",
       "3              0               0                 0                        0   \n",
       "4              0               0                 0                        0   \n",
       "5              0               0                 0                        0   \n",
       "\n",
       "   substance_syrian_rue  substance_unknown  substance_unk  \\\n",
       "1                     0                  0              0   \n",
       "2                     0                  0              0   \n",
       "3                     0                  0              0   \n",
       "4                     0                  0              0   \n",
       "5                     0                  0              0   \n",
       "\n",
       "      substance_unique_label  \n",
       "1           substance.salvia  \n",
       "2        substance.mushrooms  \n",
       "3  substance.methamphetamine  \n",
       "4              substance.lsd  \n",
       "5        substance.5_meo_dmt  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Getting to know the dataframe + pandas\n",
    "# pd.set_option('display.width', 80)\n",
    "# pd_tripReports.shape\n",
    "# pd_tripReports.info()\n",
    "# pd_tripReports.head()\n",
    "# pd_tripReports.tail()\n",
    "\n",
    "# Renaming dataframe columns to make it easier to work with\n",
    "pd_tripReports.columns = pd_tripReports.columns.str.strip().str.lower().str.replace('.', '_')\n",
    "pd_tripReports.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.1 | Retrieve the reports for different substances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "R[write to console]: Using report, title, substance, substance.unique_label as id variables\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[90m# A tibble: 6 x 2\u001b[39m\n",
      "  title                           `n()`\n",
      "  \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m                           \u001b[3m\u001b[90m<int>\u001b[39m\u001b[23m\n",
      "\u001b[90m1\u001b[39m ::: The City of Light :::          21\n",
      "\u001b[90m2\u001b[39m ... Meh                            21\n",
      "\u001b[90m3\u001b[39m ...But I Did Everything Right!     21\n",
      "\u001b[90m4\u001b[39m ...Until the Crystal Cracked!      21\n",
      "\u001b[90m5\u001b[39m ...When I'm Closing in on Death    21\n",
      "\u001b[90m6\u001b[39m .3 PPM of Our Air                  21\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-0d07c5064cd7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'R'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'-o tripReports -o tripReports.long'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'# ^ export tripReports and tripReports.long for use in python environment\\n# https://stackoverflow.com/questions/55841165/share-variables-between-r-and-python-in-jupyternotebook\\n\\n### create long data format, using report, title, substance, substance.unique_label as id variables\\n# glimpse(tripReports)\\ntripReports.long <- reshape2::melt(tripReports)\\n\\n### validate the long data format\\ntripReports.long %>% select(-report) %>% group_by(title) %>% summarize(n()) %>% head()\\n# glimpse(tripReports.long)\\n# glimpse(tripReports)\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2357\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2358\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2359\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2360\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m</Users/alextzhao/opt/anaconda3/lib/python3.7/site-packages/decorator.py:decorator-gen-130>\u001b[0m in \u001b[0;36mR\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/rpy2/ipython/rmagic.py\u001b[0m in \u001b[0;36mR\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[1;32m    782\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mlocalconverter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconverter\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    783\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m','\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 784\u001b[0;31m                     \u001b[0moutput_ipy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mro\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobalenv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    785\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshell\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0moutput_ipy\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    786\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/rpy2/robjects/environments.py\u001b[0m in \u001b[0;36mfind\u001b[0;34m(self, item, wantfun)\u001b[0m\n\u001b[1;32m     55\u001b[0m         \"\"\"\n\u001b[1;32m     56\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEnvironment\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwantfun\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwantfun\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconversion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrpy2py\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m         \u001b[0;31m# TODO: There is a design issue here. The attribute __rname__ is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0;31m# intended to store the symbol name of the R object but this is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/functools.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    838\u001b[0m                             '1 positional argument')\n\u001b[1;32m    839\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 840\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mdispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    841\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    842\u001b[0m     \u001b[0mfuncname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__name__'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'singledispatch function'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/rpy2/robjects/pandas2ri.py\u001b[0m in \u001b[0;36mrpy2py_listvector\u001b[0;34m(obj)\u001b[0m\n\u001b[1;32m    208\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mrpy2py_listvector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m'data.frame'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrclass\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 210\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrpy2py\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    211\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy2ri\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrpy2py\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/functools.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    838\u001b[0m                             '1 positional argument')\n\u001b[1;32m    839\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 840\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mdispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    841\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    842\u001b[0m     \u001b[0mfuncname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__name__'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'singledispatch function'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/rpy2/robjects/pandas2ri.py\u001b[0m in \u001b[0;36mrpy2py_dataframe\u001b[0;34m(obj)\u001b[0m\n\u001b[1;32m    217\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mrpy2py_dataframe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m     items = OrderedDict((k, rpy2py(v) if isinstance(v, Sexp) else v)\n\u001b[0;32m--> 219\u001b[0;31m                         for k, v in obj.items())\n\u001b[0m\u001b[1;32m    220\u001b[0m     \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPandasDataFrame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m     \u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrownames\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/rpy2/robjects/pandas2ri.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    216\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0mrpy2py\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mrpy2py_dataframe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 218\u001b[0;31m     items = OrderedDict((k, rpy2py(v) if isinstance(v, Sexp) else v)\n\u001b[0m\u001b[1;32m    219\u001b[0m                         for k, v in obj.items())\n\u001b[1;32m    220\u001b[0m     \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPandasDataFrame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/rpy2/robjects/vectors.py\u001b[0m in \u001b[0;36mitems\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    292\u001b[0m             \u001b[0mit_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m         \u001b[0mit_self\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 294\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mit_self\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mit_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    295\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/rpy2/robjects/vectors.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, i)\u001b[0m\n\u001b[1;32m   1305\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1306\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1307\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mconversion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrpy2py\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1309\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/functools.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    838\u001b[0m                             '1 positional argument')\n\u001b[1;32m    839\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 840\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mdispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    841\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    842\u001b[0m     \u001b[0mfuncname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__name__'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'singledispatch function'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/rpy2/robjects/pandas2ri.py\u001b[0m in \u001b[0;36mri2py_vector\u001b[0;34m(obj)\u001b[0m\n\u001b[1;32m    172\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0mrpy2py\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSexpVector\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mri2py_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 174\u001b[0;31m     \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy2ri\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrpy2py\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    175\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/functools.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    838\u001b[0m                             '1 positional argument')\n\u001b[1;32m    839\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 840\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mdispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    841\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    842\u001b[0m     \u001b[0mfuncname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__name__'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'singledispatch function'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/rpy2/robjects/numpy2ri.py\u001b[0m in \u001b[0;36mrpy2py_sexp\u001b[0;34m(obj)\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mrpy2py_sexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtypeof\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_vectortypes\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtypeof\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mRTYPES\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVECSXP\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mro\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefault_converter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrpy2py\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%R -o tripReports -o tripReports.long\n",
    "# ^ export tripReports and tripReports.long for use in python environment\n",
    "# https://stackoverflow.com/questions/55841165/share-variables-between-r-and-python-in-jupyternotebook\n",
    "\n",
    "### create long data format, using report, title, substance, substance.unique_label as id variables\n",
    "# glimpse(tripReports)\n",
    "tripReports.long <- reshape2::melt(tripReports)\n",
    "\n",
    "### validate the long data format\n",
    "tripReports.long %>% select(-report) %>% group_by(title) %>% summarize(n()) %>% head()\n",
    "# glimpse(tripReports.long)\n",
    "# glimpse(tripReports)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/alextzhao/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Use the wordcloud package to generate baseline wordclouds\n",
    "# https://github.com/amueller/word_cloud\n",
    "# https://www.datacamp.com/community/tutorials/wordcloud-python\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from os import path\n",
    "from PIL import Image\n",
    "from wordcloud import WordCloud, ImageColorGenerator\n",
    "from wordcloud import STOPWORDS as wordcloud_STOPWORDS\n",
    "import nltk\n",
    "from nltk.corpus import stopwords as nltk_stopwords\n",
    "nltk.download('stopwords')\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# # utilities to interoperate between R and pandas data frames\n",
    "# # see https://rpy2.github.io/doc/latest/html/pandas.html\n",
    "# import rpy2.robjects as ro\n",
    "# from rpy2.robjects.packages import importr\n",
    "# from rpy2.robjects import pandas2ri\n",
    "# from rpy2.robjects.conversion import localconverter\n",
    "\n",
    "# # convert the R data frame to a pandas dataframe\n",
    "# with localconverter(ro.default_converter + pandas2ri.converter):\n",
    "#   pd_tripReports = ro.conversion.rpy2py(tripReports)\n",
    "\n",
    "# NOTE: We can just read directly from the csv file that we saved earlier\n",
    "pd_tripReports = pd.read_csv(\"tripReportsEncoded.csv\", index_col=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Prepare a few substances lists for use\n",
    "\n",
    "# a list of all the substances we want word clouds for\n",
    "substances_all_list = pd_tripReports.loc[:, 'substance_mushrooms':'substance_syrian_rue'].columns.tolist()\n",
    "# [ 'mushrooms', 'lsd', 'cannabis', ... etc] for use as stopwords\n",
    "substances_all_plainstring_list = [substance.replace(\"substance_\", \"\") for substance in substances_all_list]\n",
    "\n",
    "# TODO: Prepare regexes to match with all the observed spellings of different substances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Get the text for interested substances\n",
    "# a dictionary mapping {substance_<name> : text}\n",
    "reports_text = {}\n",
    "# Concatenate with \" \" by default, TODO: Can specify separator as such: str.cat(sep=\"...\")\n",
    "for substance in substances_all_list:\n",
    "    reports_text[substance] = pd_tripReports.query(\"{} == 1\".format(substance))[\"report\"].str.cat().lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.2 | Preprossing, including stopwords analysis, tokenization, stemming, lemmatization\n",
    "\n",
    "Text preprossing procedures draws inspiration from [here](https://towardsdatascience.com/creating-word-clouds-with-python-f2077c8de5cc) and [A Practitioner's Guide to Natural Language Processing (Part I) ‚Äî Processing & Understanding Text](https://towardsdatascience.com/a-practitioners-guide-to-natural-language-processing-part-i-processing-understanding-text-9f4abfd13e72), as well as Professor `Chris Callison-Burch's` [Computational Liguistics Class](http://computational-linguistics-class.org/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1.2.1 | Prepare Stopwords\n",
    "\n",
    "The ise of stopwords (typically commonly occuring, low information content words) in natural language processing is in itself an art. Both automatic detection of stopwords (Wilbur & Sirotkin, 1992) and dictionary approaches have been widely used. For example, `nltk` has 179 stopwords , `wordcloud` package has 192 stopwords,`sklearn` has 318 stopwords, with 116 words shared between all three lists. Some examples of these shared stopwords are 'how', 'itself', 'an', 'ours', 'who', 'had', 'once', 'before', 'yours', and 'the', which are among the most common words in the English language.\n",
    "\n",
    "Here we (1) use `nltk` and `wordcloud` stopwords as a baseline (exclude `sklearn` stopwords because of [known issues](https://scikit-learn.org/stable/modules/feature_extraction.html#stop-words) and (2) add all alternative spellings of drugs observed from EDA to our stopwords list; Note that the latter is an optional, concious design decision: we can leave the drug names be (in which case they would show up disproportionately in the word clouds), or we can remove all drug names from the reports and focus on non drug names that correlate with particular reports. In total, our psychedelic drug corpus has 2783 unique spellings / mispellings of drug names. In total, our stopword list consisits of 2999 unique stopwords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['how', 'itself', 'an', 'ours', 'who', 'had', 'once', 'before', 'yours', 'am', 'some', 'no', 'be', 'but', 'her', 'after', 'your', 'then', 'for', 'his']\n"
     ]
    }
   ],
   "source": [
    "# Number of stopwords for each dictionary\n",
    "from sklearn.feature_extraction import stop_words\n",
    "len(stop_words.ENGLISH_STOP_WORDS) #sklearn\n",
    "len(nltk_stopwords.words('english')) #nltk\n",
    "len(wordcloud_STOPWORDS) #wordcloud\n",
    "len(substances_all_alternative_spellings) #all substance spellings\n",
    "\n",
    "# overlap between sklearn, nltk, and wordcloud stopwords\n",
    "overlapped_stopwords = []\n",
    "overlap_stopwords = [word for word in stop_words.ENGLISH_STOP_WORDS if word in nltk_stopwords.words('english') and word in wordcloud_STOPWORDS]\n",
    "print(overlap[:20])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2999"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Retrieve all alternative spellings for substances\n",
    "with open('substances_unique') as f:\n",
    "    substances_all_alternative_spellings = f.readlines()\n",
    "substances_all_alternative_spellings = [spelling.strip().replace(\"'\", \"\") for spelling in substances_all_alternative_spellings]\n",
    "substances_all_alternative_spellings[:30]\n",
    "\n",
    "## prepare stopwords\n",
    "stopword_list = []\n",
    "stopwords_nltk = nltk_stopwords.words('english')\n",
    "stopwords_wordcloud = list(wordcloud_STOPWORDS)\n",
    "stopword_list.extend(stopwords_nltk + stopwords_wordcloud + substances_all_alternative_spellings)\n",
    "# deduplicate list\n",
    "stopword_list = list(dict.fromkeys(stopword_list))\n",
    "\n",
    "# How many unique stopwords in total do we have?\n",
    "len(stopword_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1.2.2 | Cleaning and Tokenizing the Text\n",
    "\n",
    "To improve performance of wordclouds and subsequent processing of the reports, we use `nltk` to tokenize the text; Note that other tokenization methods may be tested for performance comparison\n",
    "\n",
    "Overview:\n",
    "- Use `nltk` for tokenization\n",
    "- Use `regex` to remove numbers\n",
    "- Use `unicodedata.normalize` to normalize accented characters\n",
    "- Make all text lowercase\n",
    "- NOTE: only unigrams considered at this stage; ngram analysis down the line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPTIONAL\n",
    "# Remove accented characters and normalise using the unicodedata library\n",
    "# from https://towardsdatascience.com/creating-word-clouds-with-python-f2077c8de5cc\\\n",
    "# TODO\n",
    "unicodedata.normalize('NFKD', text).encode('ascii', 'ignore').decode('utf-8', 'ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: Long Run Time\n",
    "\n",
    "# Tokenize the text\n",
    "reports_text_tokenized = {}\n",
    "\n",
    "# reports_text is {substance: text} mapping\n",
    "# NOTE: This code takes an extremely long time to run\n",
    "for substance in reports_text:\n",
    "    substance_text = reports_text[substance]\n",
    "    tokens = nltk.word_tokenize(substance_text)    \n",
    "    tokens = [token.strip().lower() for token in tokens]\n",
    "    substance_tokenized_text = ' '.join([token for token in tokens if token not in stopword_list])\n",
    "    \n",
    "    reports_text_tokenized[substance] = substance_tokenized_text\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because the tokenization and removal of stopwords takes a substantial amount of time to run, we store a serialized version of the object so we may retrive it later at a substantially faster rate; see [pickle tutorial](https://www.journaldev.com/15638/python-pickle-example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPTIONAL\n",
    "## Use this cell as a template to save and load large data files; current code saves and loads `reports_text_tokenized`\n",
    "\n",
    "import pickle\n",
    "\n",
    "### Stores the tokenized reports:\n",
    "# with open('reports_tokenized_map', 'wb') as out_file:\n",
    "#     pickle.dump(reports_text_tokenized, out_file)\n",
    "    \n",
    "### Loads the tokenized reports:\n",
    "with open('reports_tokenized_map', 'rb') as in_file:\n",
    "    reports_text_tokenized = pickle.load(in_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1.2.3 |  Stemming and Lemmatizing the text\n",
    "\n",
    "For our baseline results, stemming and lemmatizing is optional; nevertheless, we include the procedures here as an extension, and for the reader to explore.  \n",
    "\n",
    "`Stemming` refers to the often crude procedure of removing the ends of words to find the \"word stem\"; e.g.: walks -> walk;`Porter Stemmer`, `Lovins Stemmer`, `Paice Stemmer` are three examples of commonly used stemming algorithm. Some `Porter Stemmer` rules are found below ([source](https://nlp.stanford.edu/IR-book/html/htmledition/stemming-and-lemmatization-1.html))\n",
    "\n",
    "![Example of Porter Stemmer](images/infographic_porter-stemmer.png)\n",
    "\n",
    "`Lemmatization`, to quote verbatim [Stanford's Information Retrival Texbook](https://nlp.stanford.edu/IR-book/html/htmledition/stemming-and-lemmatization-1.html), \"usually refers to doing things properly with the use of a vocabulary and morphological analysis of words, normally aiming to remove inflectional endings only and to return the base or dictionary form of a word, which is known as the lemma\". In other words, lemmatization returns the \"cannonical\" form of a word.\n",
    "\n",
    "Some examples of lemmatization: ([source](https://www.geeksforgeeks.org/python-lemmatization-with-nltk/))\n",
    "- rocks : rock\n",
    "- corpora : corpus\n",
    "- better : good\n",
    "\n",
    "In a very real sense, lemmatization is a more complex procedure and can often produce more desirable results  \n",
    "However, it is interesting to note that with sufficiently large datasets in industrial machine learning applications (such as those done at Google), stemming and lemmatization are uncommonly used (**source**: in conversation with [Lyle Ungar](https://www.cis.upenn.edu/~ungar/))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['an upper',\n",
       " 'base',\n",
       " 'bath salt',\n",
       " 'dream herbal incense)',\n",
       " 'ecstasy (unknown',\n",
       " 'indian leaf',\n",
       " 'london underground dream)',\n",
       " 'magic silver',\n",
       " 'sensory deprivation',\n",
       " 'white rock opium',\n",
       " '(15x extract)',\n",
       " '(2c-t-7',\n",
       " '(amt + mdma)',\n",
       " '(amt + methamphetamine)',\n",
       " '(hydrocodone',\n",
       " '(methyl',\n",
       " '(quetiapine) seroquel',\n",
       " '1',\n",
       " '1 soma',\n",
       " '1-4 butanediol',\n",
       " '10x',\n",
       " '10x extract)',\n",
       " '10x extracts)',\n",
       " '15x extracts)',\n",
       " '19-norandrostenedione (nor-19)',\n",
       " '2-aminoindan',\n",
       " '2-aminoindan (im)',\n",
       " '2-c-t-2',\n",
       " '2-cb',\n",
       " '2-cd']"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# OPTIONAL\n",
    "# Lammatization\n",
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.3 | Generating Baseline Wordclouds\n",
    "\n",
    "#### 1.1.3.1 | Wordclouds Based on Word Frequency\n",
    "\n",
    "Note: Using the `wordcloud` package, we are making numerous assumptions, including:\n",
    "- Word scaling based on `frequency` only\n",
    "-  of words: the `wordcloud` package has a `relative_scaling` attribute, which specifies the importance of relative word frequencies for font-size. If `relative_scaling = 0`, the only word-ranks are considered; `relative_scaling=1` means words size is directly proportional to their frequency; Default of `relative_scaling = 0.5` considers both word frequency and word rank, and is used in our analysis. Insight retrieved from `wordcloud` [documentation](http://amueller.github.io/word_cloud/generated/wordcloud.WordCloud.html#wordcloud.WordCloud) and from [this tutorial](https://www.datacamp.com/community/tutorials/wordcloud-python)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now plotting wordclouds for 5 substances...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-6c346c932534>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# creating subplots: https://stackoverflow.com/questions/25239933/how-to-add-title-to-subplots-in-matplotlib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# changing figure size: https://stackoverflow.com/questions/332289/how-do-you-change-the-size-of-figures-drawn-with-matplotlib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msuptitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Word Clouds based on word Frequencies\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfontsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "#### Create Wordclouds\n",
    "# a list of the \"classical psychedelics\"\n",
    "substances_psychedelics_list = [\"substance_mushrooms\", \"substance_lsd\", \"substance_mescaline\", \"substance_5_meo_dmt\", \"substance_dmt\"]\n",
    "\n",
    "\n",
    "# NOTE: change this line of code to change which substances to plot\n",
    "substances_to_plot = substances_psychedelics_list\n",
    "num_plots = len(substances_to_plot)\n",
    "print(\"Now plotting wordclouds for {} substances...\".format(num_plots))\n",
    "\n",
    "# creating subplots: https://stackoverflow.com/questions/25239933/how-to-add-title-to-subplots-in-matplotlib\n",
    "# changing figure size: https://stackoverflow.com/questions/332289/how-do-you-change-the-size-of-figures-drawn-with-matplotlib\n",
    "fig = plt.figure(figsize=(50, 10))\n",
    "fig.suptitle(\"Word Clouds based on word Frequencies\", fontsize=16)\n",
    "\n",
    "for index, substance in enumerate(substances_to_plot):\n",
    "    wordcloud = WordCloud(stopwords=stopword_list, max_font_size=50, max_words=100, background_color=\"white\").generate(reports_text_tokenized[substance])\n",
    "    ax = plt.subplot(num_plots, 1, index+1) # note here for subplots index must be [1, num_plots]\n",
    "    ax.set_title(\"{} Wordcloud\".format(substance))\n",
    "    plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "plt.savefig('wordclouds_naive_psychedelics.png')\n",
    "plt.show()\n",
    "    \n",
    "\n",
    "### Plotting a single wordcloud\n",
    "# wordcloud = WordCloud(stopwords=stopwords_all, max_font_size=50, max_words=100, background_color=\"white\").generate(reports_text_tokenized[\"substance_mushrooms\"])\n",
    "# plt.figure()\n",
    "# plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
    "# plt.axis(\"off\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1.3.2 Wordclouds Based on `tf-idf`\n",
    "\n",
    "Using just the raw word frequencies, we see many of the most commonly used words are shared across all trip reports, giving us little if any insight into the most significant words that is associated with each type of substance. To improve upon the raw frequency baseline, we use use the `tf-idf` for each (word, document) pair as a weighting term.\n",
    "\n",
    "`tf-idf` stands for `term frequency-inverse document frequency`, and is specified for each (word, document) pair. It is by far one of the most widely used weighting scheme in considering how important a word is to a document, and is widely used in text mining and information retrieval. For an approachable academic introduction to `tf-idf`, see Chris Callison-Burch's [lecture slides](http://computational-linguistics-class.org/slides/05-vector-semantics.pdf)  \n",
    "\n",
    "- `tf` stands for `Term Frequency` ([Luhn 1957](http://web.stanford.edu/class/linguist289/luhn57.pdf)). The term trequency of word i in document j is given by:\n",
    "$tf_{ij}$ = # of times word $i$ appears in document $j$\n",
    "\n",
    "- `idf` stands for `Inverse Document Frequency` ([Spark Jones 1972](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.115.8343&rep=rep1&type=pdf)). The inverse document frequency of word $i$ is given by\n",
    "\n",
    "$$idf_i = log\\left(\\cfrac{N}{df_i}\\right)$$\n",
    "\n",
    "Where $df_i$ is the `document frequency of word i`, the number of documents containing word $i$  \n",
    "\n",
    "With these definitions, we stay the tf-idf weighting of word $i$ in document $j$ is given by\n",
    "\n",
    "$$ tf.idf(i,j) = tf_{ij} \\cdot idf_{i}$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Replace numbers from corpus\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.1.3.2.1 `tfidf wordclouds` >>> Using only 19 different documents\n",
    "\n",
    "We first group all the reports for a particular substance into one document, for a total of 19 documents or `samples`. Under this schema, each substance has precisely one document, which is the concatenation of all the reports corresponding to that substance. Note that there are concerns with doing this, as `idf` typically assumes a large number of documents in the corpora; we will explore an alternative approach later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## See TFidfVectorizer docs: https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from scipy.sparse.csr import csr_matrix # need this if we want to save tfidf_matrix; see https://stackoverflow.com/questions/34449127/sklearn-tfidf-transformer-how-to-get-tf-idf-values-of-given-words-in-documen\n",
    "\n",
    "\n",
    "# NOTE: reports_text_tokenized stores the tokenized corpus\n",
    "# List of substances under consideration, sorted to preserve alphabetical ordering\n",
    "substances_list_sorted = sorted(list(reports_text_tokenized.keys()))\n",
    "substances_list_sorted\n",
    "\n",
    "# TfidfVectorizer expects a list of strings, so we prepare the corpus in the appropriate format\n",
    "corpus_psychedelics_sorted = []\n",
    "for substance in substances_list_sorted:\n",
    "    corpus_psychedelics_sorted.append(reports_text_tokenized[substance])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes on the specification of TfidfVectorizer; additional information found in [documentation](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html)\n",
    "- `strip_accents=ascii` helps us strip accented characters such as `√°` to `a`\n",
    "- `lowercase=True`: automatically converts all the text to lowercase\n",
    "- `analyzer=word`: considers words as the basic unigram unit; we can also do a character level model with `char`\n",
    "- `stop_words=english`: uses built in stopwords given by `sklearn`; Follow these [instructions](https://awhan.wordpress.com/2016/06/05/scikit-learn-nlp-list-english-stopwords/) to view all the stopwords for `sklearn` and `nltk`\n",
    "- `ngram_range=(1, 1)`: setting to (1, 1) gives us unigrams. For bigrams and trigrams, we use (1, 2) and (1, 3) respectively\n",
    "- `max_df=1.0`: using the float `1.0` sets the maximum document frequency to 100\\% of the documents\n",
    "- `min_df=1`: ignores all words with document frequency less than 1\n",
    "- `max_features=None`: Don't put a cap on the number of features\n",
    "- `binary=False`: Use the tf counts, instead of setting all non-zero counts to 1\n",
    "- `dtype=float64`: Default datatype for tf-idf values\n",
    "- `norm=l2`: uses the L2 norm for each row of tf-idf values, so each row sums to 1\n",
    "- `use_idf=True`: use idf weighting (instead of just tf)\n",
    "- `smooth_idf=True`: this is akin to laplace smoothing, and helps us prevent 0 divisions\n",
    "- `sublinear_tf=False`: Do not replace tf with 1 + log(tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alextzhao/opt/anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:1616: UserWarning: Only (<class 'numpy.float64'>, <class 'numpy.float32'>, <class 'numpy.float16'>) 'dtype' should be used. float64 'dtype' will be converted to np.float64.\n",
      "  UserWarning)\n"
     ]
    }
   ],
   "source": [
    "# create and use a TfidfVectorizer\n",
    "# We specify explicitly the parameters used, even for defaults, in order to be precise with our assumptions\n",
    "# and for reproducibity\n",
    "# note: sklearn by default throws away punctuations; we accept this as we are not performing sentiment analysis\n",
    "# and related tasks where punctuations may be highly informative\n",
    "\n",
    "# https://kavita-ganesan.com/tfidftransformer-tfidfvectorizer-usage-differences/#.XeLZRzJKjmE\n",
    "vectorizer_tfidf = TfidfVectorizer(strip_accents='ascii',\n",
    "                                  lowercase=True,\n",
    "                                  analyzer='word',\n",
    "                                  stop_words='english',\n",
    "                                  ngram_range=(1, 1),\n",
    "                                  max_df=1.0,\n",
    "                                  min_df=1,\n",
    "                                  max_features=None,\n",
    "                                  vocabulary=None,\n",
    "                                  binary=False,\n",
    "                                  dtype='float64',\n",
    "                                  norm='l2',\n",
    "                                  use_idf=True,\n",
    "                                  smooth_idf=True,\n",
    "                                  sublinear_tf=False)\n",
    "\n",
    "X_vectors_tfidf = vectorizer_tfidf.fit_transform(corpus_psychedelics_sorted)\n",
    "# vectorizer_tfidf.get_feature_names()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['substance_5_meo_dmt',\n",
       " 'substance_alcohol',\n",
       " 'substance_ayahuasca',\n",
       " 'substance_cannabis',\n",
       " 'substance_dmt',\n",
       " 'substance_ibogaine',\n",
       " 'substance_kava',\n",
       " 'substance_ketamine',\n",
       " 'substance_kratom',\n",
       " 'substance_lsd',\n",
       " 'substance_mdma',\n",
       " 'substance_mescaline',\n",
       " 'substance_methamphetamine',\n",
       " 'substance_morning_glory',\n",
       " 'substance_mushrooms',\n",
       " 'substance_nitrous_oxide',\n",
       " 'substance_pcp',\n",
       " 'substance_salvia',\n",
       " 'substance_syrian_rue']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Take a look again at the sorted ordering of the substances\n",
    "substances_list_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper functions to extract keywords from documents\n",
    "# from http://kavita-ganesan.com/extracting-keywords-from-text-tfidf/#.XeLcAzJKjmE\n",
    "def sort_coo(coo_matrix):\n",
    "    tuples = zip(coo_matrix.col, coo_matrix.data)\n",
    "    return sorted(tuples, key=lambda x: (x[1], x[0]), reverse=True)\n",
    " \n",
    "def extract_topn_from_vector(feature_names, sorted_items, topn=10):\n",
    "    \"\"\"get the feature names and tf-idf score of top n items\"\"\"\n",
    "    \n",
    "    #use only topn items from vector\n",
    "    sorted_items = sorted_items[:topn]\n",
    " \n",
    "    score_vals = []\n",
    "    feature_vals = []\n",
    "    \n",
    "    # word index and corresponding tf-idf score\n",
    "    for idx, score in sorted_items:\n",
    "        \n",
    "        #keep track of feature name and its corresponding score\n",
    "        score_vals.append(round(score, 3))\n",
    "        feature_vals.append(feature_names[idx])\n",
    " \n",
    "    #create a tuples of feature,score\n",
    "    #results = zip(feature_vals,score_vals)\n",
    "    results= {}\n",
    "    for idx in range(len(feature_vals)):\n",
    "        results[feature_vals[idx]]=score_vals[idx]\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=====Doc=====\n",
      "\n",
      "===Keywords===\n",
      "seeds 0.381\n",
      "time 0.286\n",
      "experience 0.282\n",
      "felt 0.284\n"
     ]
    }
   ],
   "source": [
    "# Tutorial on how to extract key words based on tf-idf: http://kavita-ganesan.com/extracting-keywords-from-text-tfidf/#.XeLcAzJKjmE\n",
    "\n",
    "# Using the tf-idf frequencies\n",
    "feature_names_tfidf = vectorizer_tfidf.get_feature_names()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "sorted_items=sort_coo(X_vectors_tfidf.tocoo())\n",
    "\n",
    "#extract only the top n; n here is 10\n",
    "keywords=extract_topn_from_vector(feature_names_tfidf,sorted_items,10)\n",
    " \n",
    "# now print the results\n",
    "print(\"\\n=====Doc=====\")\n",
    "# print(doc[:1000])\n",
    "print(\"\\n===Keywords===\")\n",
    "for k in keywords:\n",
    "    print(k,keywords[k])\n",
    "\n",
    "    \n",
    "# # get the first vector out (for the first document)\n",
    "# first_vector_tfidfvectorizer= X_vectors_tfidf[0]\n",
    " \n",
    "# # place tf-idf values in a pandas data frame\n",
    "# df = pd.DataFrame(first_vector_tfidfvectorizer.T.todense(), index=feature_names_tfidf, columns=[\"tfidf\"])\n",
    "# df.sort_values(by=[\"tfidf\"],ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Sidebar: Some Interesting Observations from `Tfidfvectorizer` output\n",
    "It's interesting to note that looking at the Tfidfvectorizer feature_names, we see many numbers. These numbers either stand alone or are followed by units and quantifiers.  ,  \n",
    "\n",
    "These units seem to be used to specify multiple types of quantities, such as:\n",
    "- weight (that of substance ingested or user): \n",
    "    - 'c', 'g', 'gm', 'gram', 'grams', 'lbs', 'mcg', 'mg', 'microgram', 'mics', 'o', 'oz', 'pounds', 'ug'\n",
    "- volume or length\n",
    "    - 'cc', 'cm', 'cup', 'ft', 'i', 'inch', 'iu', 'kg', 'kgs', 'meters', 'metres', 'mile', 'miles', 'ml', 'sq', 'tbs', 'tbsp', 'yards'\n",
    "- time or time period\n",
    "    - \"'s' (e.g.: in 'the 1990s')\", 'XXhXXm', 'am', 'hours', 'hr', 'min', 'minute', 'pm', 'sec'\n",
    "- user age\n",
    "    - 'day', 'y', 'yo', 'yr'\n",
    "- scales and dimensions\n",
    "    - \"'5x' (e.g.: 5x salvia extract)\", '1x15', '1x50mg'\n",
    "- addresses\n",
    "    - \"st\"\n",
    "- speed\n",
    "    - \"mph\"\n",
    "- numerical quantification\n",
    "    - \"'strips' (e.g.: number of lsd strips)\", \"'ths' (as in 100ths times)\", 'nd', 'th'\n",
    "- sound information\n",
    "    - 'bpm', 'bps', 'hz'\n",
    "\n",
    "A closer examination of this numberical data may yield very interesting information about user demographics, set and setting, and dosage. All of this may be extremely valuable since dosage, set and setting, are among the most important factors in determining one's subjective experience when consuming a drug, and demographics may be correlated with the valence of a particular experience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Extension - extracting bigrams and trigrams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.1.3.2.2 TODO: `tfidf wordclouds` >>> using all documents separately with multilabel\n",
    "\n",
    "TODO: How do we handle multilabels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.4: (For Fun) Creating custom word cloud masks\n",
    "\n",
    "To make the wordclouds more interesting, we can add custom image masks to the wordclouds, as inspired by [this article](https://towardsdatascience.com/creating-word-clouds-with-python-f2077c8de5cc), [this tutorial](https://www.datacamp.com/community/tutorials/wordcloud-python), and `wordcloud` package [documentation](http://amueller.github.io/word_cloud/generated/wordcloud.WordCloud.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x1440 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Plot wordcloud with image mask\n",
    "# Make sure white parts are 255 instead of 0, as per: https://www.datacamp.com/community/tutorials/wordcloud-python\n",
    "# TODO: Why is the wordcloud blurry, and why can I not get the mask to work appropriately?\n",
    "def transform_format(val):\n",
    "    if val == 0: return 255\n",
    "    else: return val\n",
    "    \n",
    "mask_mushroom = np.array(Image.open(\"images/util_mushroom_vector_mask.png\"))\n",
    "# vectorization of transform_format function above; invert the mask to be in the right format\n",
    "mask_mushroom[mask_mushroom > 240] = 30\n",
    "mask_mushroom[mask_mushroom == 0] = 255\n",
    "mask_mushroom\n",
    "\n",
    "#plot a mushroom wordmap about mushrooms\n",
    "#increase \"resolution\": https://stackoverflow.com/questions/28786534/increase-resolution-with-word-cloud-and-remove-empty-border\n",
    "\n",
    "# wordcloud_mushroom_masked = WordCloud(width=1000, height=10000, stopwords=stopword_list, mask=mask_mushroom, max_font_size=50, max_words=100, background_color=\"black\").generate(reports_text_tokenized[\"substance_mushrooms\"])\n",
    "wordcloud_mushroom_masked = WordCloud(max_font_size=50, max_words=100, mask=mask_mushroom, stopwords=stopword_list, background_color=\"white\").generate(reports_text_tokenized[\"substance_mushrooms\"])\n",
    "\n",
    "plt.figure(figsize=(20, 20))\n",
    "plt.imshow(wordcloud_mushroom_masked, interpolation=\"bilinear\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.savefig('wordcloud_naive_mushroom_masked')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2: Wordclouds with Log Odds Ratio\n",
    "\n",
    "#### TODO\n",
    "\n",
    "This approach uses Informative Prior Log Odds IPLO ratio method, which is used in natural language processing to identify the differences in language usage patters between two groups. The foundations rests upon log odds ratio, a widely used technique in statistical inference and hypothesis testing. Intuitively, we ask, how much more likely is a word to belong to a particular document, as opposed to in another document. In a very deep way, log odds ratio relates to the F statistic in statistical inference, and is used widely for model selection.( // TODO: Cite ISLR / ESM)\n",
    "\n",
    "The theoretical framework is outlined in more detail [here](TODO) // TODO cite CCB's log odds paper\n",
    "\n",
    "In the case of multilabelled psychedelic trip reports, we can take a one-vs-all approach, i.e.: compare documents with the label `substance.mushrooms` and documents without the label `substance.mushrooms`. This will discover words / tokens that are particularly informative of the `substance.mushrooms` class. Note again that reports with a particular `substance.*` label are not necessarily uniquely `substance.*`, and may contain other labels since people have a tendency to consume multiple different types of drugs simultaneously.\n",
    "\n",
    "Code adapted from [john-hewitt](https://github.com/john-hewitt/iplo-analysis) and Chris Callison Burch's research group (reproduction with explicit permission from Callison-Burch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Logs Odds Ratio Code Adapted from Chris Callison Burch's Lab!!!\n",
    "# TODO: Implement for psychedelic trip reprots\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3: Wordclouds with other methods\n",
    "\n",
    "### TODO: \n",
    "\n",
    "- Logistic regression weights\n",
    "- Weights from other classification methods\n",
    "- LDA document embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Predicting Substance Labels from Trip Reports\n",
    "\n",
    "### TODO\n",
    "\n",
    "- Baseline: multinomial Bayes and other techniques; see sklearn [classifying text documents](https://scikit-learn.org/stable/auto_examples/text/plot_document_classification_20newsgroups.html#sphx-glr-auto-examples-text-plot-document-classification-20newsgroups-py)\n",
    "- Baseline: Logistic Regression:\n",
    "    - Coefficients returned by logistic regression can be used as weights to scale words in worclouds\n",
    "    - TODO: How do we handle the multilabel case?\n",
    "    - Appropriate regularization like LASSO / Ridge (Elastic Net) for feature selection\n",
    "- Baseline: Naive Bayes classifier\n",
    "- BERT fine-tuning\n",
    "    - [Huggingface](https://github.com/huggingface/transformers) + transformers - See Chris Callison-Burch‚Äôs recommendations\n",
    "- Handling `multilabel learning`, see [sklearn multiclass and multilabel learning](https://scikit-learn.org/stable/modules/multiclass.html#multiclass-and-multilabel-algorithms)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Using automatic piplines for text feature extraction and classification\n",
    "See sklearn [pipline example](https://scikit-learn.org/stable/auto_examples/model_selection/grid_search_text_feature_extraction.html#sphx-glr-auto-examples-model-selection-grid-search-text-feature-extraction-py)\n",
    "\n",
    "TODO: Modify to suit multi-label learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: CODE FROM https://scikit-learn.org/stable/auto_examples/model_selection/grid_search_text_feature_extraction.html#sphx-glr-auto-examples-model-selection-grid-search-text-feature-extraction-py\n",
    "\n",
    "# Author: Olivier Grisel <olivier.grisel@ensta.org>\n",
    "#         Peter Prettenhofer <peter.prettenhofer@gmail.com>\n",
    "#         Mathieu Blondel <mathieu@mblondel.org>\n",
    "# License: BSD 3 clause\n",
    "from pprint import pprint\n",
    "from time import time\n",
    "import logging\n",
    "\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "print(__doc__)\n",
    "\n",
    "# Display progress logs on stdout\n",
    "logging.basicConfig(level=logging.INFO,\n",
    "                    format='%(asctime)s %(levelname)s %(message)s')\n",
    "\n",
    "\n",
    "# #############################################################################\n",
    "# Load some categories from the training set\n",
    "categories = [\n",
    "    'alt.atheism',\n",
    "    'talk.religion.misc',\n",
    "]\n",
    "# Uncomment the following to do the analysis on all the categories\n",
    "#categories = None\n",
    "\n",
    "print(\"Loading 20 newsgroups dataset for categories:\")\n",
    "print(categories)\n",
    "\n",
    "data = fetch_20newsgroups(subset='train', categories=categories)\n",
    "print(\"%d documents\" % len(data.filenames))\n",
    "print(\"%d categories\" % len(data.target_names))\n",
    "print()\n",
    "\n",
    "# #############################################################################\n",
    "# Define a pipeline combining a text feature extractor with a simple\n",
    "# classifier\n",
    "pipeline = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', SGDClassifier(tol=1e-3)),\n",
    "])\n",
    "\n",
    "# uncommenting more parameters will give better exploring power but will\n",
    "# increase processing time in a combinatorial way\n",
    "parameters = {\n",
    "    'vect__max_df': (0.5, 0.75, 1.0),\n",
    "    # 'vect__max_features': (None, 5000, 10000, 50000),\n",
    "    'vect__ngram_range': ((1, 1), (1, 2)),  # unigrams or bigrams\n",
    "    # 'tfidf__use_idf': (True, False),\n",
    "    # 'tfidf__norm': ('l1', 'l2'),\n",
    "    'clf__max_iter': (20,),\n",
    "    'clf__alpha': (0.00001, 0.000001),\n",
    "    'clf__penalty': ('l2', 'elasticnet'),\n",
    "    # 'clf__max_iter': (10, 50, 80),\n",
    "}\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # multiprocessing requires the fork to happen in a __main__ protected\n",
    "    # block\n",
    "\n",
    "    # find the best parameters for both the feature extraction and the\n",
    "    # classifier\n",
    "    grid_search = GridSearchCV(pipeline, parameters, cv=5,\n",
    "                               n_jobs=-1, verbose=1)\n",
    "\n",
    "    print(\"Performing grid search...\")\n",
    "    print(\"pipeline:\", [name for name, _ in pipeline.steps])\n",
    "    print(\"parameters:\")\n",
    "    pprint(parameters)\n",
    "    t0 = time()\n",
    "    grid_search.fit(data.data, data.target)\n",
    "    print(\"done in %0.3fs\" % (time() - t0))\n",
    "    print()\n",
    "\n",
    "    print(\"Best score: %0.3f\" % grid_search.best_score_)\n",
    "    print(\"Best parameters set:\")\n",
    "    best_parameters = grid_search.best_estimator_.get_params()\n",
    "    for param_name in sorted(parameters.keys()):\n",
    "        print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multilabel Classification\n",
    "Using [multilabel classification example](https://scikit-learn.org/stable/auto_examples/plot_multilabel.html#multilabel-classification) from sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO: Example code from sklearn, see: https://scikit-learn.org/stable/auto_examples/plot_multilabel.html#multilabel-classification\n",
    "print(__doc__)\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.datasets import make_multilabel_classification\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cross_decomposition import CCA\n",
    "\n",
    "\n",
    "def plot_hyperplane(clf, min_x, max_x, linestyle, label):\n",
    "    # get the separating hyperplane\n",
    "    w = clf.coef_[0]\n",
    "    a = -w[0] / w[1]\n",
    "    xx = np.linspace(min_x - 5, max_x + 5)  # make sure the line is long enough\n",
    "    yy = a * xx - (clf.intercept_[0]) / w[1]\n",
    "    plt.plot(xx, yy, linestyle, label=label)\n",
    "\n",
    "\n",
    "def plot_subfigure(X, Y, subplot, title, transform):\n",
    "    if transform == \"pca\":\n",
    "        X = PCA(n_components=2).fit_transform(X)\n",
    "    elif transform == \"cca\":\n",
    "        X = CCA(n_components=2).fit(X, Y).transform(X)\n",
    "    else:\n",
    "        raise ValueError\n",
    "\n",
    "    min_x = np.min(X[:, 0])\n",
    "    max_x = np.max(X[:, 0])\n",
    "\n",
    "    min_y = np.min(X[:, 1])\n",
    "    max_y = np.max(X[:, 1])\n",
    "\n",
    "    classif = OneVsRestClassifier(SVC(kernel='linear'))\n",
    "    classif.fit(X, Y)\n",
    "\n",
    "    plt.subplot(2, 2, subplot)\n",
    "    plt.title(title)\n",
    "\n",
    "    zero_class = np.where(Y[:, 0])\n",
    "    one_class = np.where(Y[:, 1])\n",
    "    plt.scatter(X[:, 0], X[:, 1], s=40, c='gray', edgecolors=(0, 0, 0))\n",
    "    plt.scatter(X[zero_class, 0], X[zero_class, 1], s=160, edgecolors='b',\n",
    "                facecolors='none', linewidths=2, label='Class 1')\n",
    "    plt.scatter(X[one_class, 0], X[one_class, 1], s=80, edgecolors='orange',\n",
    "                facecolors='none', linewidths=2, label='Class 2')\n",
    "\n",
    "    plot_hyperplane(classif.estimators_[0], min_x, max_x, 'k--',\n",
    "                    'Boundary\\nfor class 1')\n",
    "    plot_hyperplane(classif.estimators_[1], min_x, max_x, 'k-.',\n",
    "                    'Boundary\\nfor class 2')\n",
    "    plt.xticks(())\n",
    "    plt.yticks(())\n",
    "\n",
    "    plt.xlim(min_x - .5 * max_x, max_x + .5 * max_x)\n",
    "    plt.ylim(min_y - .5 * max_y, max_y + .5 * max_y)\n",
    "    if subplot == 2:\n",
    "        plt.xlabel('First principal component')\n",
    "        plt.ylabel('Second principal component')\n",
    "        plt.legend(loc=\"upper left\")\n",
    "\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "X, Y = make_multilabel_classification(n_classes=2, n_labels=1,\n",
    "                                      allow_unlabeled=True,\n",
    "                                      random_state=1)\n",
    "\n",
    "plot_subfigure(X, Y, 1, \"With unlabeled samples + CCA\", \"cca\")\n",
    "plot_subfigure(X, Y, 2, \"With unlabeled samples + PCA\", \"pca\")\n",
    "\n",
    "X, Y = make_multilabel_classification(n_classes=2, n_labels=1,\n",
    "                                      allow_unlabeled=False,\n",
    "                                      random_state=1)\n",
    "\n",
    "plot_subfigure(X, Y, 3, \"Without unlabeled samples + CCA\", \"cca\")\n",
    "plot_subfigure(X, Y, 4, \"Without unlabeled samples + PCA\", \"pca\")\n",
    "\n",
    "plt.subplots_adjust(.04, .02, .97, .94, .09, .2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3: Topic Modelling of Trip Reports\n",
    "\n",
    "### TODO\n",
    "- Topic modelling with `Latent Dirichlet Allocation (LDA)`; see [`sklearn example`](https://scikit-learn.org/stable/auto_examples/applications/plot_topics_extraction_with_nmf_lda.html#sphx-glr-auto-examples-applications-plot-topics-extraction-with-nmf-lda-py) which uses `LDA` and `Non-negative matrix factorization (NMF)`; Also see [`LDA Documentation`](https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.LatentDirichletAllocation.html#sklearn.decomposition.LatentDirichletAllocation); Also see `gensim` package\n",
    "- As per conversation with Lyle Ungar, `LDA` can also give me document and word embeddings which can be used in wordclouds.\n",
    "- [Excellent Talk by Christine Doig on Topic Models](http://chdoig.github.io/pygotham-topic-modeling/#/)\n",
    "- [Blei 2012: Probabilistic Topic Models](http://www.cs.columbia.edu/~blei/papers/Blei2012.pdf); [local-link](./papers/Blei2012_Probabilistic-Topic-Models.pdf)\n",
    "- TODO: Latent Semantic Indexing (singular value decomposition)\n",
    "- TODO: Non-negative Matrix factorization (NMF)\n",
    "- LDA gives us two things:\n",
    "    - A document-topic matrix, which can be used as an input to wordcloud\n",
    "    - A topic-term matrix, which helps us in looking at potential topics in the corpus.\n",
    "\n",
    "- **TODO**: Explain how `Latent Dirichlet Allocation (LDA)` works; see Blei 2012 and Christine Doig's talk.\n",
    "- TODO: Investigate how to choose the number of topics, which apparently is an art in itself\n",
    "- LDA Visualizations:\n",
    "    - [LDAvis R Package](https://github.com/cpsievert/LDAvis)\n",
    "    - [LDAvis port Python Package](https://github.com/bmabey/pyLDAvis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() got an unexpected keyword argument 'n_topics'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-56-fa47cae73343>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecomposition\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLatentDirichletAllocation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mlda\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLatentDirichletAllocation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_topics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mdt_matrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv_matrix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdt_matrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'T1'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'T2'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'T3'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'n_topics'"
     ]
    }
   ],
   "source": [
    "# TODO: LDA Example code\n",
    "# Source: https://towardsdatascience.com/understanding-feature-engineering-part-3-traditional-methods-for-text-data-f6f7d70acd41\n",
    "# TODO: Looks like we can apply LDA on many different matrices, including count vector or tfidf vector\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "lda = LatentDirichletAllocation(n_topics=3, max_iter=10000, random_state=0)\n",
    "dt_matrix = lda.fit_transform(cv_matrix)\n",
    "features = pd.DataFrame(dt_matrix, columns=['T1', 'T2', 'T3'])\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: View the words for the topics\n",
    "# Source: https://towardsdatascience.com/understanding-feature-engineering-part-3-traditional-methods-for-text-data-f6f7d70acd41\n",
    "tt_matrix = lda.components_\n",
    "for topic_weights in tt_matrix:\n",
    "    topic = [(token, weight) for token, weight in zip(vocab, topic_weights)]\n",
    "    topic = sorted(topic, key=lambda x: -x[1])\n",
    "    topic = [item for item in topic if item[1] > 0.6]\n",
    "    print(topic)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset...\n",
      "done in 1.640s.\n",
      "Extracting tf-idf features for NMF...\n",
      "done in 0.435s.\n",
      "Extracting tf features for LDA...\n",
      "done in 0.431s.\n",
      "\n",
      "Fitting the NMF model (Frobenius norm) with tf-idf features, n_samples=2000 and n_features=1000...\n",
      "done in 0.407s.\n",
      "\n",
      "Topics in NMF model (Frobenius norm):\n",
      "Topic #0: just people don think like know time good make way really say right ve want did ll new use years\n",
      "Topic #1: windows use dos using window program os drivers application help software pc running ms screen files version card code work\n",
      "Topic #2: god jesus bible faith christian christ christians does heaven sin believe lord life church mary atheism belief human love religion\n",
      "Topic #3: thanks know does mail advance hi info interested email anybody looking card help like appreciated information send list video need\n",
      "Topic #4: car cars tires miles 00 new engine insurance price condition oil power speed good 000 brake year models used bought\n",
      "Topic #5: edu soon com send university internet mit ftp mail cc pub article information hope program mac email home contact blood\n",
      "Topic #6: file problem files format win sound ftp pub read save site help image available create copy running memory self version\n",
      "Topic #7: game team games year win play season players nhl runs goal hockey toronto division flyers player defense leafs bad teams\n",
      "Topic #8: drive drives hard disk floppy software card mac computer power scsi controller apple mb 00 pc rom sale problem internal\n",
      "Topic #9: key chip clipper keys encryption government public use secure enforcement phone nsa communications law encrypted security clinton used legal standard\n",
      "\n",
      "Fitting the NMF model (generalized Kullback-Leibler divergence) with tf-idf features, n_samples=2000 and n_features=1000...\n",
      "done in 1.828s.\n",
      "\n",
      "Topics in NMF model (generalized Kullback-Leibler divergence):\n",
      "Topic #0: just people don like did know make really right think say things time look way didn ve course probably good\n",
      "Topic #1: help thanks windows know hi need using does looking anybody appreciated card mail software use info email ftp available pc\n",
      "Topic #2: does god believe know mean true christians read point jesus christian church come people fact says religion say agree bible\n",
      "Topic #3: know thanks mail interested like new just bike email edu advance want contact really list heard com post hear information\n",
      "Topic #4: 10 new 30 12 20 50 11 sale 16 15 time 14 old power ago good 100 great offer cost\n",
      "Topic #5: number 1993 data subject government new numbers provide information space following com research include large note group major time talk\n",
      "Topic #6: edu problem file com remember try soon article mike files code program sun free send think cases manager little called\n",
      "Topic #7: game year team games world fact second case won said win division play best clearly claim allow example used doesn\n",
      "Topic #8: think don drive hard need bit mac make sure read apple going comes disk computer case pretty drives software ve\n",
      "Topic #9: good just use like doesn got way don ll going does chip better doing bad key want sure bit car\n",
      "\n",
      "Fitting LDA models with tf features, n_samples=2000 and n_features=1000...\n",
      "done in 6.229s.\n",
      "\n",
      "Topics in LDA model:\n",
      "Topic #0: edu com mail send graphics ftp pub available contact university list faq ca information cs 1993 program sun uk mit\n",
      "Topic #1: don like just know think ve way use right good going make sure ll point got need really time doesn\n",
      "Topic #2: christian think atheism faith pittsburgh new bible radio games alt lot just religion like book read play time subject believe\n",
      "Topic #3: drive disk windows thanks use card drives hard version pc software file using scsi help does new dos controller 16\n",
      "Topic #4: hiv health aids disease april medical care research 1993 light information study national service test led 10 page new drug\n",
      "Topic #5: god people does just good don jesus say israel way life know true fact time law want believe make think\n",
      "Topic #6: 55 10 11 18 15 team game 19 period play 23 12 13 flyers 20 25 22 17 24 16\n",
      "Topic #7: car year just cars new engine like bike good oil insurance better tires 000 thing speed model brake driving performance\n",
      "Topic #8: people said did just didn know time like went think children came come don took years say dead told started\n",
      "Topic #9: key space law government public use encryption earth section security moon probe enforcement keys states lunar military crime surface technology\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# TODO: Example code from https://scikit-learn.org/stable/auto_examples/applications/plot_topics_extraction_with_nmf_lda.html#sphx-glr-auto-examples-applications-plot-topics-extraction-with-nmf-lda-py\n",
    "\n",
    "# Author: Olivier Grisel <olivier.grisel@ensta.org>\n",
    "#         Lars Buitinck\n",
    "#         Chyi-Kwei Yau <chyikwei.yau@gmail.com>\n",
    "# License: BSD 3 clause\n",
    "\n",
    "from time import time\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.decomposition import NMF, LatentDirichletAllocation\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "n_samples = 2000\n",
    "n_features = 1000\n",
    "n_components = 10\n",
    "n_top_words = 20\n",
    "\n",
    "\n",
    "def print_top_words(model, feature_names, n_top_words):\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        message = \"Topic #%d: \" % topic_idx\n",
    "        message += \" \".join([feature_names[i]\n",
    "                             for i in topic.argsort()[:-n_top_words - 1:-1]])\n",
    "        print(message)\n",
    "    print()\n",
    "\n",
    "\n",
    "# Load the 20 newsgroups dataset and vectorize it. We use a few heuristics\n",
    "# to filter out useless terms early on: the posts are stripped of headers,\n",
    "# footers and quoted replies, and common English words, words occurring in\n",
    "# only one document or in at least 95% of the documents are removed.\n",
    "\n",
    "print(\"Loading dataset...\")\n",
    "t0 = time()\n",
    "dataset = fetch_20newsgroups(shuffle=True, random_state=1,\n",
    "                             remove=('headers', 'footers', 'quotes'))\n",
    "data_samples = dataset.data[:n_samples]\n",
    "print(\"done in %0.3fs.\" % (time() - t0))\n",
    "\n",
    "# Use tf-idf features for NMF.\n",
    "print(\"Extracting tf-idf features for NMF...\")\n",
    "tfidf_vectorizer = TfidfVectorizer(max_df=0.95, min_df=2,\n",
    "                                   max_features=n_features,\n",
    "                                   stop_words='english')\n",
    "t0 = time()\n",
    "tfidf = tfidf_vectorizer.fit_transform(data_samples)\n",
    "print(\"done in %0.3fs.\" % (time() - t0))\n",
    "\n",
    "# Use tf (raw term count) features for LDA.\n",
    "print(\"Extracting tf features for LDA...\")\n",
    "tf_vectorizer = CountVectorizer(max_df=0.95, min_df=2,\n",
    "                                max_features=n_features,\n",
    "                                stop_words='english')\n",
    "t0 = time()\n",
    "tf = tf_vectorizer.fit_transform(data_samples)\n",
    "print(\"done in %0.3fs.\" % (time() - t0))\n",
    "print()\n",
    "\n",
    "# Fit the NMF model\n",
    "print(\"Fitting the NMF model (Frobenius norm) with tf-idf features, \"\n",
    "      \"n_samples=%d and n_features=%d...\"\n",
    "      % (n_samples, n_features))\n",
    "t0 = time()\n",
    "nmf = NMF(n_components=n_components, random_state=1,\n",
    "          alpha=.1, l1_ratio=.5).fit(tfidf)\n",
    "print(\"done in %0.3fs.\" % (time() - t0))\n",
    "\n",
    "print(\"\\nTopics in NMF model (Frobenius norm):\")\n",
    "tfidf_feature_names = tfidf_vectorizer.get_feature_names()\n",
    "print_top_words(nmf, tfidf_feature_names, n_top_words)\n",
    "\n",
    "# Fit the NMF model\n",
    "print(\"Fitting the NMF model (generalized Kullback-Leibler divergence) with \"\n",
    "      \"tf-idf features, n_samples=%d and n_features=%d...\"\n",
    "      % (n_samples, n_features))\n",
    "t0 = time()\n",
    "nmf = NMF(n_components=n_components, random_state=1,\n",
    "          beta_loss='kullback-leibler', solver='mu', max_iter=1000, alpha=.1,\n",
    "          l1_ratio=.5).fit(tfidf)\n",
    "print(\"done in %0.3fs.\" % (time() - t0))\n",
    "\n",
    "print(\"\\nTopics in NMF model (generalized Kullback-Leibler divergence):\")\n",
    "tfidf_feature_names = tfidf_vectorizer.get_feature_names()\n",
    "print_top_words(nmf, tfidf_feature_names, n_top_words)\n",
    "\n",
    "print(\"Fitting LDA models with tf features, \"\n",
    "      \"n_samples=%d and n_features=%d...\"\n",
    "      % (n_samples, n_features))\n",
    "lda = LatentDirichletAllocation(n_components=n_components, max_iter=5,\n",
    "                                learning_method='online',\n",
    "                                learning_offset=50.,\n",
    "                                random_state=0)\n",
    "t0 = time()\n",
    "lda.fit(tf)\n",
    "print(\"done in %0.3fs.\" % (time() - t0))\n",
    "\n",
    "print(\"\\nTopics in LDA model:\")\n",
    "tf_feature_names = tf_vectorizer.get_feature_names()\n",
    "print_top_words(lda, tf_feature_names, n_top_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 4: Trip Reports Generation\n",
    "\n",
    "### TODO\n",
    "- Hidden Markov Model baseline\n",
    "- LSTM baselines\n",
    "    - Character Model\n",
    "    - Word model\n",
    "- Finetuning BERT to generate trip reports\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 5: Other ways of Visualizing Trip reports\n",
    "\n",
    "- Clustering with ordinary `K-means` and `minibatch K-means`; see [sklearn example](https://scikit-learn.org/stable/auto_examples/text/plot_document_clustering.html#sphx-glr-auto-examples-text-plot-document-clustering-py)\n",
    "- `Principle Components Analysis (PCA)` of trip reports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading 20news dataset. This may take a few minutes.\n",
      "2019-11-30 00:37:12,265 INFO Downloading 20news dataset. This may take a few minutes.\n",
      "Downloading dataset from https://ndownloader.figshare.com/files/5975967 (14 MB)\n",
      "2019-11-30 00:37:12,270 INFO Downloading dataset from https://ndownloader.figshare.com/files/5975967 (14 MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatically created module for IPython interactive environment\n",
      "Usage: ipykernel_launcher.py [options]\n",
      "\n",
      "Options:\n",
      "  -h, --help            show this help message and exit\n",
      "  --lsa=N_COMPONENTS    Preprocess documents with latent semantic analysis.\n",
      "  --no-minibatch        Use ordinary k-means algorithm (in batch mode).\n",
      "  --no-idf              Disable Inverse Document Frequency feature weighting.\n",
      "  --use-hashing         Use a hashing feature vectorizer\n",
      "  --n-features=N_FEATURES\n",
      "                        Maximum number of features (dimensions) to extract\n",
      "                        from text.\n",
      "  --verbose             Print progress reports inside k-means algorithm.\n",
      "Loading 20 newsgroups dataset for categories:\n",
      "['alt.atheism', 'talk.religion.misc', 'comp.graphics', 'sci.space']\n",
      "3387 documents\n",
      "4 categories\n",
      "\n",
      "Extracting features from the training dataset using a sparse vectorizer\n",
      "done in 1.086469s\n",
      "n_samples: 3387, n_features: 10000\n",
      "\n",
      "Clustering sparse data with MiniBatchKMeans(batch_size=1000, compute_labels=True, init='k-means++',\n",
      "                init_size=1000, max_iter=100, max_no_improvement=10,\n",
      "                n_clusters=4, n_init=1, random_state=None,\n",
      "                reassignment_ratio=0.01, tol=0.0, verbose=False)\n",
      "done in 0.154s\n",
      "\n",
      "Homogeneity: 0.539\n",
      "Completeness: 0.572\n",
      "V-measure: 0.555\n",
      "Adjusted Rand-Index: 0.576\n",
      "Silhouette Coefficient: 0.007\n",
      "\n",
      "Top terms per cluster:\n",
      "Cluster 0: god people jesus say don believe christian bible com religion\n",
      "Cluster 1: graphics university image thanks ac files uk file com 3d\n",
      "Cluster 2: space com nasa access henry digex gov article pat toronto\n",
      "Cluster 3: sandvik keith sgi com livesey kent caltech apple newton solntze\n"
     ]
    }
   ],
   "source": [
    "# TODO: Example code from: https://scikit-learn.org/stable/auto_examples/text/plot_document_clustering.html#sphx-glr-auto-examples-text-plot-document-clustering-py\n",
    "\n",
    "# Author: Peter Prettenhofer <peter.prettenhofer@gmail.com>\n",
    "#         Lars Buitinck\n",
    "# License: BSD 3 clause\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn import metrics\n",
    "\n",
    "from sklearn.cluster import KMeans, MiniBatchKMeans\n",
    "\n",
    "import logging\n",
    "from optparse import OptionParser\n",
    "import sys\n",
    "from time import time\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Display progress logs on stdout\n",
    "logging.basicConfig(level=logging.INFO,\n",
    "                    format='%(asctime)s %(levelname)s %(message)s')\n",
    "\n",
    "# parse commandline arguments\n",
    "op = OptionParser()\n",
    "op.add_option(\"--lsa\",\n",
    "              dest=\"n_components\", type=\"int\",\n",
    "              help=\"Preprocess documents with latent semantic analysis.\")\n",
    "op.add_option(\"--no-minibatch\",\n",
    "              action=\"store_false\", dest=\"minibatch\", default=True,\n",
    "              help=\"Use ordinary k-means algorithm (in batch mode).\")\n",
    "op.add_option(\"--no-idf\",\n",
    "              action=\"store_false\", dest=\"use_idf\", default=True,\n",
    "              help=\"Disable Inverse Document Frequency feature weighting.\")\n",
    "op.add_option(\"--use-hashing\",\n",
    "              action=\"store_true\", default=False,\n",
    "              help=\"Use a hashing feature vectorizer\")\n",
    "op.add_option(\"--n-features\", type=int, default=10000,\n",
    "              help=\"Maximum number of features (dimensions)\"\n",
    "                   \" to extract from text.\")\n",
    "op.add_option(\"--verbose\",\n",
    "              action=\"store_true\", dest=\"verbose\", default=False,\n",
    "              help=\"Print progress reports inside k-means algorithm.\")\n",
    "\n",
    "print(__doc__)\n",
    "op.print_help()\n",
    "\n",
    "\n",
    "def is_interactive():\n",
    "    return not hasattr(sys.modules['__main__'], '__file__')\n",
    "\n",
    "\n",
    "# work-around for Jupyter notebook and IPython console\n",
    "argv = [] if is_interactive() else sys.argv[1:]\n",
    "(opts, args) = op.parse_args(argv)\n",
    "if len(args) > 0:\n",
    "    op.error(\"this script takes no arguments.\")\n",
    "    sys.exit(1)\n",
    "\n",
    "\n",
    "# #############################################################################\n",
    "# Load some categories from the training set\n",
    "categories = [\n",
    "    'alt.atheism',\n",
    "    'talk.religion.misc',\n",
    "    'comp.graphics',\n",
    "    'sci.space',\n",
    "]\n",
    "# Uncomment the following to do the analysis on all the categories\n",
    "# categories = None\n",
    "\n",
    "print(\"Loading 20 newsgroups dataset for categories:\")\n",
    "print(categories)\n",
    "\n",
    "dataset = fetch_20newsgroups(subset='all', categories=categories,\n",
    "                             shuffle=True, random_state=42)\n",
    "\n",
    "print(\"%d documents\" % len(dataset.data))\n",
    "print(\"%d categories\" % len(dataset.target_names))\n",
    "print()\n",
    "\n",
    "labels = dataset.target\n",
    "true_k = np.unique(labels).shape[0]\n",
    "\n",
    "print(\"Extracting features from the training dataset \"\n",
    "      \"using a sparse vectorizer\")\n",
    "t0 = time()\n",
    "if opts.use_hashing:\n",
    "    if opts.use_idf:\n",
    "        # Perform an IDF normalization on the output of HashingVectorizer\n",
    "        hasher = HashingVectorizer(n_features=opts.n_features,\n",
    "                                   stop_words='english', alternate_sign=False,\n",
    "                                   norm=None, binary=False)\n",
    "        vectorizer = make_pipeline(hasher, TfidfTransformer())\n",
    "    else:\n",
    "        vectorizer = HashingVectorizer(n_features=opts.n_features,\n",
    "                                       stop_words='english',\n",
    "                                       alternate_sign=False, norm='l2',\n",
    "                                       binary=False)\n",
    "else:\n",
    "    vectorizer = TfidfVectorizer(max_df=0.5, max_features=opts.n_features,\n",
    "                                 min_df=2, stop_words='english',\n",
    "                                 use_idf=opts.use_idf)\n",
    "X = vectorizer.fit_transform(dataset.data)\n",
    "\n",
    "print(\"done in %fs\" % (time() - t0))\n",
    "print(\"n_samples: %d, n_features: %d\" % X.shape)\n",
    "print()\n",
    "\n",
    "if opts.n_components:\n",
    "    print(\"Performing dimensionality reduction using LSA\")\n",
    "    t0 = time()\n",
    "    # Vectorizer results are normalized, which makes KMeans behave as\n",
    "    # spherical k-means for better results. Since LSA/SVD results are\n",
    "    # not normalized, we have to redo the normalization.\n",
    "    svd = TruncatedSVD(opts.n_components)\n",
    "    normalizer = Normalizer(copy=False)\n",
    "    lsa = make_pipeline(svd, normalizer)\n",
    "\n",
    "    X = lsa.fit_transform(X)\n",
    "\n",
    "    print(\"done in %fs\" % (time() - t0))\n",
    "\n",
    "    explained_variance = svd.explained_variance_ratio_.sum()\n",
    "    print(\"Explained variance of the SVD step: {}%\".format(\n",
    "        int(explained_variance * 100)))\n",
    "\n",
    "    print()\n",
    "\n",
    "\n",
    "# #############################################################################\n",
    "# Do the actual clustering\n",
    "\n",
    "if opts.minibatch:\n",
    "    km = MiniBatchKMeans(n_clusters=true_k, init='k-means++', n_init=1,\n",
    "                         init_size=1000, batch_size=1000, verbose=opts.verbose)\n",
    "else:\n",
    "    km = KMeans(n_clusters=true_k, init='k-means++', max_iter=100, n_init=1,\n",
    "                verbose=opts.verbose)\n",
    "\n",
    "print(\"Clustering sparse data with %s\" % km)\n",
    "t0 = time()\n",
    "km.fit(X)\n",
    "print(\"done in %0.3fs\" % (time() - t0))\n",
    "print()\n",
    "\n",
    "print(\"Homogeneity: %0.3f\" % metrics.homogeneity_score(labels, km.labels_))\n",
    "print(\"Completeness: %0.3f\" % metrics.completeness_score(labels, km.labels_))\n",
    "print(\"V-measure: %0.3f\" % metrics.v_measure_score(labels, km.labels_))\n",
    "print(\"Adjusted Rand-Index: %.3f\"\n",
    "      % metrics.adjusted_rand_score(labels, km.labels_))\n",
    "print(\"Silhouette Coefficient: %0.3f\"\n",
    "      % metrics.silhouette_score(X, km.labels_, sample_size=1000))\n",
    "\n",
    "print()\n",
    "\n",
    "\n",
    "if not opts.use_hashing:\n",
    "    print(\"Top terms per cluster:\")\n",
    "\n",
    "    if opts.n_components:\n",
    "        original_space_centroids = svd.inverse_transform(km.cluster_centers_)\n",
    "        order_centroids = original_space_centroids.argsort()[:, ::-1]\n",
    "    else:\n",
    "        order_centroids = km.cluster_centers_.argsort()[:, ::-1]\n",
    "\n",
    "    terms = vectorizer.get_feature_names()\n",
    "    for i in range(true_k):\n",
    "        print(\"Cluster %d:\" % i, end='')\n",
    "        for ind in order_centroids[i, :10]:\n",
    "            print(' %s' % terms[ind], end='')\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appendix: archived code, explanations, and miscellaneous musings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['report', 'title', 'substance']\n",
      "[\"After having had some success with other forms of legal highs, I decided to experiment with salvia.  I had heard it was an intense but short acting psychedelic, which intrigued me.  Although I have loved psychedelics since I first discovered them eight years ago, I dont use them that often in part because of the time involved in tripping and analyzing the experience.  That said I have used psychedelics somewhere around three dozen times in my life.  My favorite method of tripping is LSD, but I have also used mushrooms, morning glory and baby woodrose seeds.  I have also used a variety of other drugs, including stimulants, depressants, empathogens, and deleriants.\\n\\n\\n\\nI ordered salvia online, choosing a 5x extract.  When the package arrived my husband wanted to try it immediately.  I prefer to prepare more for trips but knowing the effects werent supposed to last very long I said why not?  My husband, who uses psychedelics rarely now but used them a lot when he was younger, went first.  He took a large hit from our glass pipe.  He coughed a lot but reported no initial effects.  Only two minutes later he took two smaller but decent sized hits.  He started to smile that tripped out smile and I knew it had hit him.  He was silent but looked around like everything was captivating.  After a few minutes I asked how he felt and he said great and started to laugh.  He described a pouring feeling as though he was being poured into his body.  When he had recovered a bit more he told me it was like acid, which surprised me as the reports I read were not really acidlike.  He stumbled a bit but seemed to be mostly normal after ten minutes.  I asked him to hand me the pipe when he felt sober enough to babysit me and he handed it over five minutes later (15 minutes after smoking).\\n\\n\\n\\nHere is where I made a big mistake.  Seeing that it had required 3 hits to get my husband off, I decided to take two hits.  I had read enough reports to know better, but the extremely short duration of the trip made me feel safe.  I took the first hit slowly and smoothly (a pleasant smoke I might add), holding it in for about 20 seconds.  I blew out a huge cloud of smoke, and started to take another hit.  Halfway through the second hit (while still inhaling) I got tunnel vision.  I hardly felt the smoke leave my lungs.  The whole room was spinning and everything had trails.  I was shocked and amazed at the change in my surroundings.  It was like a cross between shroom trails and the bed spins (like from too much alcohol).  I felt two things at once.  Part of me was feeling totally disoriented and wanted everything to stop moving.  And part of me was having fun.  I realized that if I looked at the center of the room things were much better and I started to laugh really hard.  I was in ecstasy and in pain.\\n\\n\\n\\nThen the center of the room began to spin wildly too.  I felt like I was in the hold of a ship being thrashed about by massive waves.  My husband was standing half on the balcony smoking.  At this point he walked in a step and said Welcome to my world.  At that instant the whole room landed hard on its side, taking my husband and me with it.  Gravity was now pulling me in towards the kitchen, which is normally North.  South, the direction of the balcony, was up.  Both me and my husband were stuck sideways, our legs dangling in the air, inches from the kitchen counter's side, which was now the floor.  I was able to move my parts around my center of gravity, but not able to move my center of gravity.  I did not fall to the 'floor' because I was caught in the grip of two opposing forces.  One at my back and the other at my front.\\n\\n\\n\\nI was certain that I had been sucked into an alternate dimension or world, which I called sideways world.  This was what my husband meant when he said welcome to my world, or so I thought at the time. Although this new world had definite direction it was spinning about this new axis at lightening speed. I kept trying to turn, hoping that a new perspective would stop everything, but I felt as much as saw the added trails this caused.  In fact my whole body was spinning and contracting around its axis, which ran down the spine.  This was highly painful and utterly terrifying.  I have had scary moments on drugs before but nothing that comes close to this.  I didnt know that fear could be like that.  I had had one terrifying moment of clarity in a dream once, when I knew that there was no afterlife and that my consciousness would cease to exist.  This rivaled that dream in the fear department but was far more frantic.\\n\\n\\n\\nI hated my husband for damning me to this world.  I knew that it was a drug experience, and that it would end, but I had forgotten how long it would take and thought I would be like this for hours.  I was certain that he was sideways too, that he knew what this drug would do to me and let me do it anyway, so that he wouldn't be alone in this sideways world.  I looked at the door to the balcony.  The door my husband had stepped through before he turned over.  It was salvation.  The way out.  The door to the straight world.  I tried very hard to reach that door, but the world was spinning too wildly and all I could do was spin about my axis.  The door seemed to be closer at times and farther at others but I dont recall ever making progress toward it or moving away.  I yelled at my husband for putting me here, though I wasnt sure if the words came out.  I remember him talking to me but I was too frantic to listen.  His answers made no sense either.  In response to something I said he replied But Im from this world.  This struck me as utterly stupid.  He had walked into the sideways world through that door.  I saw him do it.  How could he deny it?  But as I told him this something clicked.\\n\\n\\n\\nThat door wasnt the door to the straight world!  At the same time the spinning slowed and I realized I was coming down.  Thank God!  I lay on the couch for several minutes, letting the feeling slip away.  Still terrified and in pain but now with the knowledge that it was ending.  All I had to do was wait.\\n\\n\\n\\nWhen the last of the terror had subsided I sat up and looked around.  Things were glowy and trippy like the come up of acid and I felt stoned with a mdma edge.  This lasted for about half an hour and was great.  If this was all salvia did I would smoke it all the time.  I no longer felt fear at all but a sense of awe at what the drug had done to me.  My hubby was obviously very shaken.  I knew I put him through a lot and told him several times that I was better now.  As the come down progressed I discussed my experience with him and discovered that what he saw was quite different from what I had perceived.\\n\\n\\n\\nFor his point of view, everything was fine at first.  I was laughing for at least three minutes and appeared to be enjoying myself (though in reality the fear was already there).  He stepped in after finishing a cigarette and said Welcome to my world because everything was funny to him too.  At this point I apparently jumped up and said I had to get out of this world.  I ran for the balcony door and my husband, afraid I meant to jump off the balcony, stopped me.  The next five minutes were a drag out physical struggle in which I constantly lunged for the door while he restrained me and tried to talk me down.  He said he told me a lot of things that I have no memory of.  I was also yelling and screaming at the top of my lungs.  Hubby was afraid someone would call the cops with all the ruckus I was causing.  Most of this time I was on the floor, but I fought my way up again (apparently I managed to get up several times which is surprising because my husband is much stronger than I am physically) and he put me on the couch were I lay and went limp for the first time.  This is were I came back to reality.\\n\\n\\n\\nA few days later I decided to try again, this time with less salvia.  I did not want to experience a full salvia trip again but was curious where this powerful drug might take me with more caution.  I filled the pipe bowl with a 80/20 mixture of mugwort (gives a nice stoned feeling) and salvia.  I smoked this in two hits and found myself in the happy glowy MDMA like state that I had experienced before as a come down.  I waited 5 minutes and nothing else happened so I made another bowl with a half and half mixture of the same drugs.  A hit of that put me in a deeper trip.  I experience the same feeling but with far less intensity.  This time it was the closet door that I felt I needed to go to.  I closed my eyes and buried my head in my husbands shirt until the feeling past.  I can see how many people see tunnels on salvia, since I keep focusing on doors.  After this second attempt I realized that salvia was going to keep taking me to the same place until I had a better idea of where I wanted to go and how to get there.\\n\\n\\n\\nI came away from this trip terrified of salvia but also deeply intrigued.  Someday I would like to try it again, at a smaller dose and with more preparation.  This drug has the power to take me somewhere amazing but I am not ready for it yet.\", 'Sideways World', 'Salvia divinorum (5x extract)']\n"
     ]
    }
   ],
   "source": [
    "# Explore the dataset trips.csv\n",
    "import csv\n",
    "printed = 0\n",
    "with open('trips.csv') as f:\n",
    "  csv_reader = csv.reader(f)\n",
    "  for line in csv_reader:\n",
    "    if printed < 2:\n",
    "        print(line)\n",
    "        printed += 1\n",
    "    else:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Issues Encoutered, and solutions\n",
    "\n",
    "- Python not working:  \n",
    "`brew install python`  \n",
    "`brew update python`  \n",
    "- Need to update xcode command line tools after every major / minor os upgrade: `xcode-select --install`; see [here](https://stackoverflow.com/questions/52522565/git-is-not-working-after-macos-update-xcrun-error-invalid-active-developer-pa)\n",
    "\n",
    "- Issues with installing [wordcloud](https://www.datacamp.com/community/tutorials/wordcloud-python)\n",
    "- TODO: Write an article explaining managing python versions on Mac, using both `Anacoda` and `pip`\n",
    "- Cannot do `brew link <packageName>`; see [here](https://github.com/caskformula/homebrew-caskformula/issues/10)\n",
    "- Adding `autocompletion` to jupyter notebook with [this tool](https://github.com/ipython-contrib/jupyter_contrib_nbextensions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fun (Optional) things\n",
    "- Add [animated progress nav](https://lab.hakim.se/progress-nav/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
